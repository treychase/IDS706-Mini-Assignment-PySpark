{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a8750d57",
            "metadata": {},
            "source": [
                "# Statcast Baseball Data Analysis (2017-2021)\n",
                "## Comprehensive PySpark Pipeline with Filters, Joins, Aggregations, SQL, Performance Analysis, Caching, and ML\n",
                "\n",
                "This notebook demonstrates:\n",
                "- Loading and combining 5 years of Statcast CSV data (2017-2021)\n",
                "- Filtering, joining, and aggregation operations\n",
                "- SQL queries with optimizations\n",
                "- Performance analysis with .explain() and caching benchmarks\n",
                "- Actions vs Transformations demo\n",
                "- Machine Learning example (classification or regression)\n",
                "\n",
                "**Data Source**: Statcast pitch-level baseball data from MLB"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "c03595fc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING: Using incubator modules: jdk.incubator.vector\n",
                        "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
                        "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
                        "25/11/10 19:23:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
                        "25/11/10 19:23:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Spark version: 4.0.1\n",
                        "Spark UI: http://127.0.0.1:4040\n"
                    ]
                }
            ],
            "source": [
                "# Initialize PySpark and imports\n",
                "from pyspark.sql import SparkSession\n",
                "from pyspark.sql.functions import *\n",
                "from pyspark.sql.types import *\n",
                "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
                "from pyspark.ml.classification import RandomForestClassifier\n",
                "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
                "from pyspark import StorageLevel\n",
                "import time\n",
                "import os\n",
                "\n",
                "# Initialize Spark with optimized settings\n",
                "spark = SparkSession.builder \\\n",
                "    .appName(\"Statcast_Analysis\") \\\n",
                "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
                "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
                "    .config(\"spark.local.ip\", \"127.0.0.1\") \\\n",
                "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
                "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
                "    .config(\"spark.driver.memory\", \"8g\") \\\n",
                "    .config(\"spark.executor.memory\", \"8g\") \\\n",
                "    .config(\"spark.network.timeout\", \"600s\") \\\n",
                "    .config(\"spark.rpc.askTimeout\", \"600s\") \\\n",
                "    .config(\"spark.executor.heartbeatInterval\", \"60s\") \\\n",
                "    .getOrCreate()\n",
                "\n",
                "print(f\"Spark version: {spark.version}\")\n",
                "print(f\"Spark UI: {spark.sparkContext.uiWebUrl}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "7e75138a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 5 CSV files:\n",
                        "  - data/Statcast_2018.csv\n",
                        "  - data/Statcast_2019.csv\n",
                        "  - data/Statcast_2020.csv\n",
                        "  - data/Statcast_2021.csv\n",
                        "  - data/statcast_2017.csv\n",
                        "\n",
                        "Loading data/Statcast_2018.csv...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Schema columns: 93\n",
                        "  Rows: 721,190\n",
                        "\n",
                        "Loading data/Statcast_2019.csv...\n",
                        "  Rows: 721,190\n",
                        "\n",
                        "Loading data/Statcast_2019.csv...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Schema columns: 93\n",
                        "  Rows: 732,473\n",
                        "\n",
                        "Loading data/Statcast_2020.csv...\n",
                        "  Rows: 732,473\n",
                        "\n",
                        "Loading data/Statcast_2020.csv...\n",
                        "  Schema columns: 93\n",
                        "  Rows: 264,747\n",
                        "\n",
                        "Loading data/Statcast_2021.csv...\n",
                        "  Schema columns: 93\n",
                        "  Rows: 264,747\n",
                        "\n",
                        "Loading data/Statcast_2021.csv...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Schema columns: 93\n",
                        "  Rows: 709,851\n",
                        "\n",
                        "Loading data/statcast_2017.csv...\n",
                        "  Rows: 709,851\n",
                        "\n",
                        "Loading data/statcast_2017.csv...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Schema columns: 93\n",
                        "  Rows: 721,244\n",
                        "  Rows: 721,244\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Combined dataset shape: 3,149,505 rows, 93 columns\n",
                        "\n",
                        "First few rows:\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "25/11/10 19:23:19 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+---+----------+----------+-------------+-------------+-------------+--------------+------+-------+---------+---------------+--------+--------------------+----------------------+-----------------------+----+-----------------------------------+---------+-----+--------+---------+---------+----+------------+-------+-----+-------+---------+-----+-----+-------+-------+-----+-----+-----+------------+------+-------------+----+----+--------------+-------------------+---------+------+-----+----------------+-------------------+------------------+------------------+------------------+-------------------+------+------+---------------+------------+------------+---------------+-----------------+-----------------+-------+---------+-----------+---------+---------+---------+---------+---------+---------+---------+-------------+-----------------------------+-------------------------------+----------+----------+-----------+---------+------------------+-------------+------------+----------+----------+----------+---------+---------+---------------+---------------+--------------+--------------+---------------------+---------------------+---------+------------------+---------------------+\n",
                        "|_c0|pitch_type|game_date |release_speed|release_pos_x|release_pos_z|player_name   |batter|pitcher|events   |description    |spin_dir|spin_rate_deprecated|break_angle_deprecated|break_length_deprecated|zone|des                                |game_type|stand|p_throws|home_team|away_team|type|hit_location|bb_type|balls|strikes|game_year|pfx_x|pfx_z|plate_x|plate_z|on_3b|on_2b|on_1b|outs_when_up|inning|inning_topbot|hc_x|hc_y|tfs_deprecated|tfs_zulu_deprecated|fielder_2|umpire|sv_id|vx0             |vy0                |vz0               |ax                |ay                |az                 |sz_top|sz_bot|hit_distance_sc|launch_speed|launch_angle|effective_speed|release_spin_rate|release_extension|game_pk|pitcher.1|fielder_2.1|fielder_3|fielder_4|fielder_5|fielder_6|fielder_7|fielder_8|fielder_9|release_pos_y|estimated_ba_using_speedangle|estimated_woba_using_speedangle|woba_value|woba_denom|babip_value|iso_value|launch_speed_angle|at_bat_number|pitch_number|pitch_name|home_score|away_score|bat_score|fld_score|post_away_score|post_home_score|post_bat_score|post_fld_score|if_fielding_alignment|of_fielding_alignment|spin_axis|delta_home_win_exp|delta_run_exp        |\n",
                        "+---+----------+----------+-------------+-------------+-------------+--------------+------+-------+---------+---------------+--------+--------------------+----------------------+-----------------------+----+-----------------------------------+---------+-----+--------+---------+---------+----+------------+-------+-----+-------+---------+-----+-----+-------+-------+-----+-----+-----+------------+------+-------------+----+----+--------------+-------------------+---------+------+-----+----------------+-------------------+------------------+------------------+------------------+-------------------+------+------+---------------+------------+------------+---------------+-----------------+-----------------+-------+---------+-----------+---------+---------+---------+---------+---------+---------+---------+-------------+-----------------------------+-------------------------------+----------+----------+-----------+---------+------------------+-------------+------------+----------+----------+----------+---------+---------+---------------+---------------+--------------+--------------+---------------------+---------------------+---------+------------------+---------------------+\n",
                        "|251|FC        |2018-10-01|92.2         |-1.97        |6.26         |Jansen, Kenley|467827|445276 |strikeout|swinging_strike|NULL    |NULL                |NULL                  |NULL                   |12  |Gerardo Parra strikes out swinging.|R        |L    |R       |LAD      |COL      |S   |2           |NULL   |0    |2      |2018     |0.39 |1.34 |0.63   |3.52   |NULL |NULL |NULL |2           |9     |Top          |NULL|NULL|NULL          |NULL               |518735   |NULL  |NULL |5.84804468536917|-134.451705323775  |-4.26285739377669 |3.7162242221332096|25.412307055194002|-14.7756731423349  |3.32  |1.51  |NULL           |NULL        |NULL        |94.1           |2629             |7.0              |570335 |445276   |518735     |641355   |571771   |457759   |592518   |592626   |621035   |624577   |53.52        |NULL                         |NULL                           |0.0       |1         |0          |0        |NULL              |71           |4           |Cutter    |5         |2         |2        |5        |2              |5              |2             |5             |Standard             |Standard             |164      |0.004             |-0.059000000000000004|\n",
                        "|254|FC        |2018-10-01|93.0         |-1.77        |6.3          |Jansen, Kenley|467827|445276 |NULL     |foul           |NULL    |NULL                |NULL                  |NULL                   |12  |Gerardo Parra strikes out swinging.|R        |L    |R       |LAD      |COL      |S   |NULL        |NULL   |0    |2      |2018     |0.52 |1.26 |1.09   |2.44   |NULL |NULL |NULL |2           |9     |Top          |NULL|NULL|NULL          |NULL               |518735   |NULL  |NULL |6.24412081358062|-135.41608143866898|-7.075825877656059|5.34458105199604  |27.081217454702898|-15.0090305900069  |3.32  |1.51  |NULL           |NULL        |NULL        |94.6           |2686             |7.0              |570335 |445276   |518735     |641355   |571771   |457759   |592518   |592626   |621035   |624577   |53.5         |NULL                         |NULL                           |NULL      |NULL      |NULL       |NULL     |NULL              |71           |3           |Cutter    |5         |2         |2        |5        |2              |5              |2             |5             |Standard             |Standard             |158      |0.0               |0.0                  |\n",
                        "|263|FC        |2018-10-01|91.6         |-1.75        |6.22         |Jansen, Kenley|467827|445276 |NULL     |called_strike  |NULL    |NULL                |NULL                  |NULL                   |5   |Gerardo Parra strikes out swinging.|R        |L    |R       |LAD      |COL      |S   |NULL        |NULL   |0    |1      |2018     |0.64 |1.14 |-0.17  |2.41   |NULL |NULL |NULL |2           |9     |Top          |NULL|NULL|NULL          |NULL               |518735   |NULL  |NULL |2.60244203209943|-133.52643158068   |-6.43655160487046 |7.33714243628989  |26.6083696590701  |-16.953718947633902|3.36  |1.68  |NULL           |NULL        |NULL        |93.4           |2581             |7.1              |570335 |445276   |518735     |641355   |571771   |457759   |592518   |592626   |621035   |624577   |53.4         |NULL                         |NULL                           |NULL      |NULL      |NULL       |NULL     |NULL              |71           |2           |Cutter    |5         |2         |2        |5        |2              |5              |2             |5             |Standard             |Standard             |151      |0.0               |-0.025               |\n",
                        "+---+----------+----------+-------------+-------------+-------------+--------------+------+-------+---------+---------------+--------+--------------------+----------------------+-----------------------+----+-----------------------------------+---------+-----+--------+---------+---------+----+------------+-------+-----+-------+---------+-----+-----+-------+-------+-----+-----+-----+------------+------+-------------+----+----+--------------+-------------------+---------+------+-----+----------------+-------------------+------------------+------------------+------------------+-------------------+------+------+---------------+------------+------------+---------------+-----------------+-----------------+-------+---------+-----------+---------+---------+---------+---------+---------+---------+---------+-------------+-----------------------------+-------------------------------+----------+----------+-----------+---------+------------------+-------------+------------+----------+----------+----------+---------+---------+---------------+---------------+--------------+--------------+---------------------+---------------------+---------+------------------+---------------------+\n",
                        "only showing top 3 rows\n",
                        "\n",
                        "Schema:\n",
                        "root\n",
                        " |-- _c0: integer (nullable = true)\n",
                        " |-- pitch_type: string (nullable = true)\n",
                        " |-- game_date: date (nullable = true)\n",
                        " |-- release_speed: double (nullable = true)\n",
                        " |-- release_pos_x: double (nullable = true)\n",
                        " |-- release_pos_z: double (nullable = true)\n",
                        " |-- player_name: string (nullable = true)\n",
                        " |-- batter: integer (nullable = true)\n",
                        " |-- pitcher: integer (nullable = true)\n",
                        " |-- events: string (nullable = true)\n",
                        " |-- description: string (nullable = true)\n",
                        " |-- spin_dir: string (nullable = true)\n",
                        " |-- spin_rate_deprecated: string (nullable = true)\n",
                        " |-- break_angle_deprecated: string (nullable = true)\n",
                        " |-- break_length_deprecated: string (nullable = true)\n",
                        " |-- zone: integer (nullable = true)\n",
                        " |-- des: string (nullable = true)\n",
                        " |-- game_type: string (nullable = true)\n",
                        " |-- stand: string (nullable = true)\n",
                        " |-- p_throws: string (nullable = true)\n",
                        " |-- home_team: string (nullable = true)\n",
                        " |-- away_team: string (nullable = true)\n",
                        " |-- type: string (nullable = true)\n",
                        " |-- hit_location: integer (nullable = true)\n",
                        " |-- bb_type: string (nullable = true)\n",
                        " |-- balls: integer (nullable = true)\n",
                        " |-- strikes: integer (nullable = true)\n",
                        " |-- game_year: integer (nullable = true)\n",
                        " |-- pfx_x: double (nullable = true)\n",
                        " |-- pfx_z: double (nullable = true)\n",
                        " |-- plate_x: double (nullable = true)\n",
                        " |-- plate_z: double (nullable = true)\n",
                        " |-- on_3b: integer (nullable = true)\n",
                        " |-- on_2b: integer (nullable = true)\n",
                        " |-- on_1b: integer (nullable = true)\n",
                        " |-- outs_when_up: integer (nullable = true)\n",
                        " |-- inning: integer (nullable = true)\n",
                        " |-- inning_topbot: string (nullable = true)\n",
                        " |-- hc_x: double (nullable = true)\n",
                        " |-- hc_y: double (nullable = true)\n",
                        " |-- tfs_deprecated: string (nullable = true)\n",
                        " |-- tfs_zulu_deprecated: string (nullable = true)\n",
                        " |-- fielder_2: integer (nullable = true)\n",
                        " |-- umpire: string (nullable = true)\n",
                        " |-- sv_id: string (nullable = true)\n",
                        " |-- vx0: double (nullable = true)\n",
                        " |-- vy0: double (nullable = true)\n",
                        " |-- vz0: double (nullable = true)\n",
                        " |-- ax: double (nullable = true)\n",
                        " |-- ay: double (nullable = true)\n",
                        " |-- az: double (nullable = true)\n",
                        " |-- sz_top: double (nullable = true)\n",
                        " |-- sz_bot: double (nullable = true)\n",
                        " |-- hit_distance_sc: integer (nullable = true)\n",
                        " |-- launch_speed: double (nullable = true)\n",
                        " |-- launch_angle: integer (nullable = true)\n",
                        " |-- effective_speed: double (nullable = true)\n",
                        " |-- release_spin_rate: integer (nullable = true)\n",
                        " |-- release_extension: double (nullable = true)\n",
                        " |-- game_pk: integer (nullable = true)\n",
                        " |-- pitcher.1: integer (nullable = true)\n",
                        " |-- fielder_2.1: integer (nullable = true)\n",
                        " |-- fielder_3: integer (nullable = true)\n",
                        " |-- fielder_4: integer (nullable = true)\n",
                        " |-- fielder_5: integer (nullable = true)\n",
                        " |-- fielder_6: integer (nullable = true)\n",
                        " |-- fielder_7: integer (nullable = true)\n",
                        " |-- fielder_8: integer (nullable = true)\n",
                        " |-- fielder_9: integer (nullable = true)\n",
                        " |-- release_pos_y: double (nullable = true)\n",
                        " |-- estimated_ba_using_speedangle: double (nullable = true)\n",
                        " |-- estimated_woba_using_speedangle: double (nullable = true)\n",
                        " |-- woba_value: double (nullable = true)\n",
                        " |-- woba_denom: integer (nullable = true)\n",
                        " |-- babip_value: integer (nullable = true)\n",
                        " |-- iso_value: integer (nullable = true)\n",
                        " |-- launch_speed_angle: integer (nullable = true)\n",
                        " |-- at_bat_number: integer (nullable = true)\n",
                        " |-- pitch_number: integer (nullable = true)\n",
                        " |-- pitch_name: string (nullable = true)\n",
                        " |-- home_score: integer (nullable = true)\n",
                        " |-- away_score: integer (nullable = true)\n",
                        " |-- bat_score: integer (nullable = true)\n",
                        " |-- fld_score: integer (nullable = true)\n",
                        " |-- post_away_score: integer (nullable = true)\n",
                        " |-- post_home_score: integer (nullable = true)\n",
                        " |-- post_bat_score: integer (nullable = true)\n",
                        " |-- post_fld_score: integer (nullable = true)\n",
                        " |-- if_fielding_alignment: string (nullable = true)\n",
                        " |-- of_fielding_alignment: string (nullable = true)\n",
                        " |-- spin_axis: integer (nullable = true)\n",
                        " |-- delta_home_win_exp: double (nullable = true)\n",
                        " |-- delta_run_exp: double (nullable = true)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "25/11/10 19:23:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
                        " Header: , pitch_type, game_date, release_speed, release_pos_x, release_pos_z, player_name, batter, pitcher, events, description, spin_dir, spin_rate_deprecated, break_angle_deprecated, break_length_deprecated, zone, des, game_type, stand, p_throws, home_team, away_team, type, hit_location, bb_type, balls, strikes, game_year, pfx_x, pfx_z, plate_x, plate_z, on_3b, on_2b, on_1b, outs_when_up, inning, inning_topbot, hc_x, hc_y, tfs_deprecated, tfs_zulu_deprecated, fielder_2, umpire, sv_id, vx0, vy0, vz0, ax, ay, az, sz_top, sz_bot, hit_distance_sc, launch_speed, launch_angle, effective_speed, release_spin_rate, release_extension, game_pk, pitcher.1, fielder_2.1, fielder_3, fielder_4, fielder_5, fielder_6, fielder_7, fielder_8, fielder_9, release_pos_y, estimated_ba_using_speedangle, estimated_woba_using_speedangle, woba_value, woba_denom, babip_value, iso_value, launch_speed_angle, at_bat_number, pitch_number, pitch_name, home_score, away_score, bat_score, fld_score, post_away_score, post_home_score, post_bat_score, post_fld_score, if_fielding_alignment, of_fielding_alignment, spin_axis, delta_home_win_exp, delta_run_exp\n",
                        " Schema: _c0, pitch_type, game_date, release_speed, release_pos_x, release_pos_z, player_name, batter, pitcher, events, description, spin_dir, spin_rate_deprecated, break_angle_deprecated, break_length_deprecated, zone, des, game_type, stand, p_throws, home_team, away_team, type, hit_location, bb_type, balls, strikes, game_year, pfx_x, pfx_z, plate_x, plate_z, on_3b, on_2b, on_1b, outs_when_up, inning, inning_topbot, hc_x, hc_y, tfs_deprecated, tfs_zulu_deprecated, fielder_2, umpire, sv_id, vx0, vy0, vz0, ax, ay, az, sz_top, sz_bot, hit_distance_sc, launch_speed, launch_angle, effective_speed, release_spin_rate, release_extension, game_pk, pitcher.1, fielder_2.1, fielder_3, fielder_4, fielder_5, fielder_6, fielder_7, fielder_8, fielder_9, release_pos_y, estimated_ba_using_speedangle, estimated_woba_using_speedangle, woba_value, woba_denom, babip_value, iso_value, launch_speed_angle, at_bat_number, pitch_number, pitch_name, home_score, away_score, bat_score, fld_score, post_away_score, post_home_score, post_bat_score, post_fld_score, if_fielding_alignment, of_fielding_alignment, spin_axis, delta_home_win_exp, delta_run_exp\n",
                        "Expected: _c0 but found: \n",
                        "CSV file: file:///workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2018.csv\n"
                    ]
                }
            ],
            "source": [
                "# Load and combine all Statcast CSV files (2017-2021)\n",
                "import glob\n",
                "\n",
                "data_dir = \"data\"\n",
                "csv_files = sorted(glob.glob(os.path.join(data_dir, \"[Ss]tatcast_*.csv\")))\n",
                "print(f\"Found {len(csv_files)} CSV files:\")\n",
                "for f in csv_files:\n",
                "    print(f\"  - {f}\")\n",
                "\n",
                "# Load each CSV and combine with union\n",
                "dfs = []\n",
                "for csv_file in csv_files:\n",
                "    print(f\"\\nLoading {csv_file}...\")\n",
                "    df = spark.read.csv(csv_file, header=True, inferSchema=True)\n",
                "    print(f\"  Schema columns: {len(df.columns)}\")\n",
                "    print(f\"  Rows: {df.count():,}\")\n",
                "    dfs.append(df)\n",
                "\n",
                "# Union all dataframes\n",
                "from functools import reduce\n",
                "df_raw = reduce(lambda x, y: x.union(y), dfs)\n",
                "\n",
                "print(f\"\\nCombined dataset shape: {df_raw.count():,} rows, {len(df_raw.columns)} columns\")\n",
                "print(\"\\nFirst few rows:\")\n",
                "df_raw.show(3, truncate=False)\n",
                "print(\"\\nSchema:\")\n",
                "df_raw.printSchema()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "10a59348",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "After Filter 1 (non-null): 3,133,830 rows\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "After Filter 2 (valid speeds): 3,133,809 rows\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "After transformations: 3,133,809 rows\n",
                        "\n",
                        "Sample transformed data:\n",
                        "+-------+------+----------+-------------+-----------+-----------+-----------+-------------+\n",
                        "|pitcher|batter|pitch_type|release_speed|is_fastball|is_breaking|is_offspeed|game_year_int|\n",
                        "+-------+------+----------+-------------+-----------+-----------+-----------+-------------+\n",
                        "| 445276|467827|        FC|         92.2|          1|          0|          0|         2018|\n",
                        "| 445276|467827|        FC|         93.0|          1|          0|          0|         2018|\n",
                        "| 445276|467827|        FC|         91.6|          1|          0|          0|         2018|\n",
                        "| 445276|467827|        SI|         93.1|          0|          0|          0|         2018|\n",
                        "| 445276|435622|        FC|         91.4|          1|          0|          0|         2018|\n",
                        "+-------+------+----------+-------------+-----------+-----------+-----------+-------------+\n",
                        "only showing top 5 rows\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Pitcher stats (100+ pitches): 1,307 pitchers\n",
                        "Top 5 by pitch count:\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+-------+-----------+-----------------+-----------------+--------------+--------------+--------------+\n",
                        "|pitcher|pitch_count|avg_release_speed|max_release_speed|fastball_count|breaking_count|offspeed_count|\n",
                        "+-------+-----------+-----------------+-----------------+--------------+--------------+--------------+\n",
                        "| 543037|      14172|92.08850550381035|            101.5|          7710|          5205|          1229|\n",
                        "| 458681|      13425|91.25009310986962|             98.8|         11280|           938|           459|\n",
                        "| 453286|      13381|89.29963380913237|             98.4|          7627|          3747|          2007|\n",
                        "| 571578|      13328|86.38987094837935|             95.9|          5890|          5600|           682|\n",
                        "| 605400|      13325| 86.6576885553471|             96.4|          6009|          4093|          2571|\n",
                        "+-------+-----------+-----------------+-----------------+--------------+--------------+--------------+\n",
                        "only showing top 5 rows\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "After join with pitcher stats: 3,133,809 rows\n",
                        "Sample of joined data:\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[Stage 52:=========================================>             (45 + 12) / 60]\r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+-------+-------------+-----------------+\n",
                        "|pitcher|release_speed|pitcher_avg_speed|\n",
                        "+-------+-------------+-----------------+\n",
                        "| 445276|         92.2| 91.4382815823054|\n",
                        "| 445276|         93.0| 91.4382815823054|\n",
                        "| 445276|         91.6| 91.4382815823054|\n",
                        "| 445276|         93.1| 91.4382815823054|\n",
                        "| 445276|         91.4| 91.4382815823054|\n",
                        "+-------+-------------+-----------------+\n",
                        "only showing top 5 rows\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                }
            ],
            "source": [
                "# BLOCK 1: Filters, Joins, Aggregations, and Column Transformations\n",
                "# ====================================================================\n",
                "\n",
                "# Filter 1: Remove rows with null critical columns and filter for valid pitch types\n",
                "df_filtered_1 = df_raw.filter(\n",
                "    col(\"pitch_type\").isNotNull() &\n",
                "    col(\"release_speed\").isNotNull() &\n",
                "    col(\"pitcher\").isNotNull() &\n",
                "    col(\"batter\").isNotNull()\n",
                ")\n",
                "print(f\"After Filter 1 (non-null): {df_filtered_1.count():,} rows\")\n",
                "\n",
                "# Filter 2: Valid pitch parameters (realistic speeds and positions)\n",
                "df_filtered_2 = df_filtered_1.filter(\n",
                "    (col(\"release_speed\") > 40) &  # Minimum realistic pitch speed\n",
                "    (col(\"release_speed\") < 110) &  # Maximum realistic pitch speed\n",
                "    col(\"pitcher\").isNotNull() &\n",
                "    col(\"batter\").isNotNull()\n",
                ")\n",
                "print(f\"After Filter 2 (valid speeds): {df_filtered_2.count():,} rows\")\n",
                "\n",
                "# Column Transformations using withColumn\n",
                "# Create new features from existing columns\n",
                "df_transformed = df_filtered_2 \\\n",
                "    .withColumn(\"pitch_speed_mph\", col(\"release_speed\")) \\\n",
                "    .withColumn(\"is_fastball\", when(col(\"pitch_type\").isin(\"FF\", \"FT\", \"FC\", \"FS\"), 1).otherwise(0)) \\\n",
                "    .withColumn(\"is_breaking\", when(col(\"pitch_type\").isin(\"CU\", \"SL\", \"KC\", \"EP\"), 1).otherwise(0)) \\\n",
                "    .withColumn(\"is_offspeed\", when(col(\"pitch_type\").isin(\"CH\", \"SC\"), 1).otherwise(0)) \\\n",
                "    .withColumn(\"effective_speed\", coalesce(col(\"effective_speed\"), col(\"release_speed\"))) \\\n",
                "    .withColumn(\"launch_speed_filled\", coalesce(col(\"launch_speed\"), lit(0))) \\\n",
                "    .withColumn(\"game_year_int\", col(\"game_year\").cast(\"int\"))\n",
                "\n",
                "print(f\"\\nAfter transformations: {df_transformed.count():,} rows\")\n",
                "print(\"\\nSample transformed data:\")\n",
                "df_transformed.select(\n",
                "    \"pitcher\", \"batter\", \"pitch_type\", \"release_speed\", \n",
                "    \"is_fastball\", \"is_breaking\", \"is_offspeed\", \"game_year_int\"\n",
                ").show(5)\n",
                "\n",
                "# COMPLEX AGGREGATION: Pitcher performance stats (using groupBy + agg)\n",
                "pitcher_stats = df_transformed.groupBy(\"pitcher\").agg(\n",
                "    count(\"*\").alias(\"pitch_count\"),\n",
                "    avg(\"release_speed\").alias(\"avg_release_speed\"),\n",
                "    max(\"release_speed\").alias(\"max_release_speed\"),\n",
                "    sum(\"is_fastball\").alias(\"fastball_count\"),\n",
                "    sum(\"is_breaking\").alias(\"breaking_count\"),\n",
                "    sum(\"is_offspeed\").alias(\"offspeed_count\")\n",
                ").filter(col(\"pitch_count\") > 100)  # Only pitchers with 100+ pitches\n",
                "\n",
                "print(f\"\\nPitcher stats (100+ pitches): {pitcher_stats.count():,} pitchers\")\n",
                "print(\"Top 5 by pitch count:\")\n",
                "pitcher_stats.orderBy(desc(\"pitch_count\")).show(5)\n",
                "\n",
                "# JOIN: Join pitcher stats with batter stats\n",
                "batter_stats = df_transformed.groupBy(\"batter\").agg(\n",
                "    count(\"*\").alias(\"at_bat_count\"),\n",
                "    avg(\"launch_speed_filled\").alias(\"avg_launch_speed\"),\n",
                "    sum(when(col(\"type\") == \"X\", 1).otherwise(0)).alias(\"balls_in_play\")\n",
                ").filter(col(\"at_bat_count\") > 50)\n",
                "\n",
                "# Join on pitcher and batter (example: pitcher/batter matchups)\n",
                "df_with_pitcher_batter = df_transformed.join(\n",
                "    pitcher_stats.select(\"pitcher\", col(\"avg_release_speed\").alias(\"pitcher_avg_speed\")),\n",
                "    on=\"pitcher\",\n",
                "    how=\"left\"\n",
                ")\n",
                "\n",
                "print(f\"\\nAfter join with pitcher stats: {df_with_pitcher_batter.count():,} rows\")\n",
                "print(\"Sample of joined data:\")\n",
                "df_with_pitcher_batter.select(\n",
                "    \"pitcher\", \"release_speed\", \"pitcher_avg_speed\"\n",
                ").show(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "1ea970a0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== SQL Query 1: Top Pitchers by Average Release Speed ===\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+-------+-----------+-------------+-------------+--------------+--------------+--------------+\n",
                        "|pitcher|pitch_count|avg_speed_mph|max_speed_mph|fastball_count|breaking_count|offspeed_count|\n",
                        "+-------+-----------+-------------+-------------+--------------+--------------+--------------+\n",
                        "| 661403|       1401|        97.65|        102.6|          1013|           388|             0|\n",
                        "| 663855|       1916|        96.78|        105.0|            82|           435|            28|\n",
                        "| 594027|       2018|        96.36|        104.0|          1599|           399|            20|\n",
                        "| 621237|       3323|        96.01|        102.5|           654|           371|             0|\n",
                        "| 660813|        958|        95.97|        102.3|            85|           292|             4|\n",
                        "| 623395|        929|        95.79|        101.1|           702|           142|            84|\n",
                        "| 642770|        435|        95.65|        101.7|           108|           102|            11|\n",
                        "| 662253|        433|         95.5|        102.8|           293|           140|             0|\n",
                        "| 572096|       1668|        95.35|        101.7|          1205|           293|           156|\n",
                        "| 453344|       1085|        95.16|        101.1|           953|           132|             0|\n",
                        "+-------+-----------+-------------+-------------+--------------+--------------+--------------+\n",
                        "\n",
                        "\n",
                        "=== SQL Query 2: Pitch Type Distribution by Year ===\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+-------------+----------+------+-----+\n",
                        "|game_year_int|pitch_type| count|  pct|\n",
                        "+-------------+----------+------+-----+\n",
                        "|         2017|        FF|249463|34.78|\n",
                        "|         2017|        SL|116415|16.23|\n",
                        "|         2017|        FT| 92917|12.95|\n",
                        "|         2017|        CH| 71250| 9.93|\n",
                        "|         2017|        SI| 56501| 7.88|\n",
                        "|         2017|        CU| 56406| 7.86|\n",
                        "|         2017|        FC| 38024| 5.30|\n",
                        "|         2017|        KC| 21295| 2.97|\n",
                        "|         2017|        FS| 11811| 1.65|\n",
                        "|         2017|        KN|  2646| 0.37|\n",
                        "|         2017|        FO|   247| 0.03|\n",
                        "|         2017|        EP|   185| 0.03|\n",
                        "|         2017|        PO|   116| 0.02|\n",
                        "|         2017|        SC|    39| 0.01|\n",
                        "|         2018|        FF|252196|35.16|\n",
                        "|         2018|        SL|121088|16.88|\n",
                        "|         2018|        FT| 77603|10.82|\n",
                        "|         2018|        CH| 74748|10.42|\n",
                        "|         2018|        SI| 63123| 8.80|\n",
                        "|         2018|        CU| 57488| 8.02|\n",
                        "+-------------+----------+------+-----+\n",
                        "only showing top 20 rows\n",
                        "\n",
                        "=== Writing optimized results to CSV ===\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Query 1 results written to ./output/top_pitchers\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[Stage 69:============================================>          (49 + 11) / 60]\r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Query 2 results written to ./output/pitch_distribution\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                }
            ],
            "source": [
                "# BLOCK 2: SQL Queries with Optimization\n",
                "# ========================================\n",
                "# Key optimization principles:\n",
                "# 1. Apply filters early (pushed down to scan)\n",
                "# 2. Use partitioning when writing (by year, pitch type, etc.)\n",
                "# 3. Avoid unnecessary shuffles (use broadcasting for small tables)\n",
                "# 4. Select only needed columns (column pruning)\n",
                "\n",
                "# Create temp views for SQL queries\n",
                "spark.sql(\"DROP VIEW IF EXISTS statcast_view\")\n",
                "df_with_pitcher_batter.createOrReplaceTempView(\"statcast_view\")\n",
                "\n",
                "spark.sql(\"DROP VIEW IF EXISTS pitcher_stats_view\")\n",
                "pitcher_stats.createOrReplaceTempView(\"pitcher_stats_view\")\n",
                "\n",
                "# SQL Query 1: Top pitchers by average release speed (with filter pushed down early)\n",
                "# Filter early: WHERE on pitch_count BEFORE aggregation in subquery\n",
                "print(\"\\n=== SQL Query 1: Top Pitchers by Average Release Speed ===\")\n",
                "query1 = \"\"\"\n",
                "SELECT \n",
                "    pitcher,\n",
                "    pitch_count,\n",
                "    ROUND(avg_release_speed, 2) as avg_speed_mph,\n",
                "    ROUND(max_release_speed, 2) as max_speed_mph,\n",
                "    fastball_count,\n",
                "    breaking_count,\n",
                "    offspeed_count\n",
                "FROM pitcher_stats_view\n",
                "WHERE pitch_count >= 200\n",
                "ORDER BY avg_release_speed DESC\n",
                "LIMIT 10\n",
                "\"\"\"\n",
                "result1 = spark.sql(query1)\n",
                "result1.show()\n",
                "\n",
                "# SQL Query 2: Pitch type distribution by year (with grouping and filtering)\n",
                "# Filter early on game_year to partition data\n",
                "print(\"\\n=== SQL Query 2: Pitch Type Distribution by Year ===\")\n",
                "query2 = \"\"\"\n",
                "SELECT \n",
                "    game_year_int,\n",
                "    pitch_type,\n",
                "    COUNT(*) as count,\n",
                "    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (PARTITION BY game_year_int), 2) as pct\n",
                "FROM statcast_view\n",
                "WHERE pitch_type IS NOT NULL AND release_speed > 50\n",
                "GROUP BY game_year_int, pitch_type\n",
                "ORDER BY game_year_int, count DESC\n",
                "\"\"\"\n",
                "result2 = spark.sql(query2)\n",
                "result2.show(20)\n",
                "\n",
                "# Write both results to CSV with partitioning\n",
                "print(\"\\n=== Writing optimized results to CSV ===\")\n",
                "output_dir_1 = \"./output/top_pitchers\"\n",
                "output_dir_2 = \"./output/pitch_distribution\"\n",
                "\n",
                "# Coalesce to reduce number of output files\n",
                "result1.coalesce(1).write.mode(\"overwrite\").csv(output_dir_1, header=True)\n",
                "print(f\"Query 1 results written to {output_dir_1}\")\n",
                "\n",
                "result2.coalesce(1).write.mode(\"overwrite\").csv(output_dir_2, header=True)\n",
                "print(f\"Query 2 results written to {output_dir_2}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "103db877",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== PERFORMANCE ANALYSIS ===\n",
                        "\n",
                        "1. PHYSICAL EXECUTION PLAN (from Query 2)\n",
                        "\n",
                        "Explaining the SQL query 2 (pitch type distribution):\n",
                        "== Parsed Logical Plan ==\n",
                        "'Sort ['game_year_int ASC NULLS FIRST, 'count DESC NULLS LAST], true\n",
                        "+- 'Aggregate ['game_year_int, 'pitch_type], ['game_year_int, 'pitch_type, 'COUNT(1) AS count#3749, 'ROUND(((100.0 * 'COUNT(1)) / 'SUM('COUNT(1)) windowspecdefinition('game_year_int, unspecifiedframe$())), 2) AS pct#3750]\n",
                        "   +- 'Filter (isnotnull('pitch_type) AND ('release_speed > 50))\n",
                        "      +- 'UnresolvedRelation [statcast_view], [], false\n",
                        "\n",
                        "== Analyzed Logical Plan ==\n",
                        "game_year_int: int, pitch_type: string, count: bigint, pct: decimal(27,2)\n",
                        "Sort [game_year_int#2489 ASC NULLS FIRST, count#3749L DESC NULLS LAST], true\n",
                        "+- Project [game_year_int#2489, pitch_type#18, count#3749L, pct#3750]\n",
                        "   +- Project [game_year_int#2489, pitch_type#18, count#3749L, _w0#3755L, _we0#3756L, round(((100.0 * cast(_w0#3755L as decimal(20,0))) / cast(_we0#3756L as decimal(20,0))), 2) AS pct#3750]\n",
                        "      +- Window [sum(_w0#3755L) windowspecdefinition(game_year_int#2489, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS _we0#3756L], [game_year_int#2489]\n",
                        "         +- Aggregate [game_year_int#2489, pitch_type#18], [game_year_int#2489, pitch_type#18, count(1) AS count#3749L, count(1) AS _w0#3755L]\n",
                        "            +- Filter (isnotnull(pitch_type#18) AND (release_speed#20 > cast(50 as double)))\n",
                        "               +- SubqueryAlias statcast_view\n",
                        "                  +- View (`statcast_view`, [pitcher#25, _c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 75 more fields])\n",
                        "                     +- Project [pitcher#25, _c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 75 more fields]\n",
                        "                        +- Join LeftOuter, (pitcher#25 = pitcher#3031)\n",
                        "                           :- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 74 more fields]\n",
                        "                           :  +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 73 more fields]\n",
                        "                           :     +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 72 more fields]\n",
                        "                           :        +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 72 more fields]\n",
                        "                           :           +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 71 more fields]\n",
                        "                           :              +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 70 more fields]\n",
                        "                           :                 +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 69 more fields]\n",
                        "                           :                    +- Filter ((((release_speed#20 > cast(40 as double)) AND (release_speed#20 < cast(110 as double))) AND isnotnull(pitcher#25)) AND isnotnull(batter#24))\n",
                        "                           :                       +- Filter (((isnotnull(pitch_type#18) AND isnotnull(release_speed#20)) AND isnotnull(pitcher#25)) AND isnotnull(batter#24))\n",
                        "                           :                          +- Union false, false\n",
                        "                           :                             :- Relation [_c0#17,pitch_type#18,game_date#19,release_speed#20,release_pos_x#21,release_pos_z#22,player_name#23,batter#24,pitcher#25,events#26,description#27,spin_dir#28,spin_rate_deprecated#29,break_angle_deprecated#30,break_length_deprecated#31,zone#32,des#33,game_type#34,stand#35,p_throws#36,home_team#37,away_team#38,type#39,hit_location#40,bb_type#41,... 68 more fields] csv\n",
                        "                           :                             :- Relation [_c0#224,pitch_type#225,game_date#226,release_speed#227,release_pos_x#228,release_pos_z#229,player_name#230,batter#231,pitcher#232,events#233,description#234,spin_dir#235,spin_rate_deprecated#236,break_angle_deprecated#237,break_length_deprecated#238,zone#239,des#240,game_type#241,stand#242,p_throws#243,home_team#244,away_team#245,type#246,hit_location#247,bb_type#248,... 68 more fields] csv\n",
                        "                           :                             :- Relation [_c0#431,pitch_type#432,game_date#433,release_speed#434,release_pos_x#435,release_pos_z#436,player_name#437,batter#438,pitcher#439,events#440,description#441,spin_dir#442,spin_rate_deprecated#443,break_angle_deprecated#444,break_length_deprecated#445,zone#446,des#447,game_type#448,stand#449,p_throws#450,home_team#451,away_team#452,type#453,hit_location#454,bb_type#455,... 68 more fields] csv\n",
                        "                           :                             :- Relation [_c0#638,pitch_type#639,game_date#640,release_speed#641,release_pos_x#642,release_pos_z#643,player_name#644,batter#645,pitcher#646,events#647,description#648,spin_dir#649,spin_rate_deprecated#650,break_angle_deprecated#651,break_length_deprecated#652,zone#653,des#654,game_type#655,stand#656,p_throws#657,home_team#658,away_team#659,type#660,hit_location#661,bb_type#662,... 68 more fields] csv\n",
                        "                           :                             +- Relation [_c0#845,pitch_type#846,game_date#847,release_speed#848,release_pos_x#849,release_pos_z#850,player_name#851,batter#852,pitcher#853,events#854,description#855,spin_dir#856,spin_rate_deprecated#857,break_angle_deprecated#858,break_length_deprecated#859,zone#860,des#861,game_type#862,stand#863,p_throws#864,home_team#865,away_team#866,type#867,hit_location#868,bb_type#869,... 68 more fields] csv\n",
                        "                           +- Project [pitcher#3031, avg_release_speed#2696 AS pitcher_avg_speed#3022]\n",
                        "                              +- Filter (pitch_count#2695L > cast(100 as bigint))\n",
                        "                                 +- Aggregate [pitcher#3031], [pitcher#3031, count(1) AS pitch_count#2695L, avg(release_speed#3026) AS avg_release_speed#2696, max(release_speed#3026) AS max_release_speed#2697, sum(is_fastball#3489) AS fastball_count#2698L, sum(is_breaking#3490) AS breaking_count#2699L, sum(is_offspeed#3491) AS offspeed_count#2700L]\n",
                        "                                    +- Project [_c0#3023, pitch_type#3024, game_date#3025, release_speed#3026, release_pos_x#3027, release_pos_z#3028, player_name#3029, batter#3030, pitcher#3031, events#3032, description#3033, spin_dir#3034, spin_rate_deprecated#3035, break_angle_deprecated#3036, break_length_deprecated#3037, zone#3038, des#3039, game_type#3040, stand#3041, p_throws#3042, home_team#3043, away_team#3044, type#3045, hit_location#3046, bb_type#3047, ... 74 more fields]\n",
                        "                                       +- Project [_c0#3023, pitch_type#3024, game_date#3025, release_speed#3026, release_pos_x#3027, release_pos_z#3028, player_name#3029, batter#3030, pitcher#3031, events#3032, description#3033, spin_dir#3034, spin_rate_deprecated#3035, break_angle_deprecated#3036, break_length_deprecated#3037, zone#3038, des#3039, game_type#3040, stand#3041, p_throws#3042, home_team#3043, away_team#3044, type#3045, hit_location#3046, bb_type#3047, ... 73 more fields]\n",
                        "                                          +- Project [_c0#3023, pitch_type#3024, game_date#3025, release_speed#3026, release_pos_x#3027, release_pos_z#3028, player_name#3029, batter#3030, pitcher#3031, events#3032, description#3033, spin_dir#3034, spin_rate_deprecated#3035, break_angle_deprecated#3036, break_length_deprecated#3037, zone#3038, des#3039, game_type#3040, stand#3041, p_throws#3042, home_team#3043, away_team#3044, type#3045, hit_location#3046, bb_type#3047, ... 72 more fields]\n",
                        "                                             +- Project [_c0#3023, pitch_type#3024, game_date#3025, release_speed#3026, release_pos_x#3027, release_pos_z#3028, player_name#3029, batter#3030, pitcher#3031, events#3032, description#3033, spin_dir#3034, spin_rate_deprecated#3035, break_angle_deprecated#3036, break_length_deprecated#3037, zone#3038, des#3039, game_type#3040, stand#3041, p_throws#3042, home_team#3043, away_team#3044, type#3045, hit_location#3046, bb_type#3047, ... 72 more fields]\n",
                        "                                                +- Project [_c0#3023, pitch_type#3024, game_date#3025, release_speed#3026, release_pos_x#3027, release_pos_z#3028, player_name#3029, batter#3030, pitcher#3031, events#3032, description#3033, spin_dir#3034, spin_rate_deprecated#3035, break_angle_deprecated#3036, break_length_deprecated#3037, zone#3038, des#3039, game_type#3040, stand#3041, p_throws#3042, home_team#3043, away_team#3044, type#3045, hit_location#3046, bb_type#3047, ... 71 more fields]\n",
                        "                                                   +- Project [_c0#3023, pitch_type#3024, game_date#3025, release_speed#3026, release_pos_x#3027, release_pos_z#3028, player_name#3029, batter#3030, pitcher#3031, events#3032, description#3033, spin_dir#3034, spin_rate_deprecated#3035, break_angle_deprecated#3036, break_length_deprecated#3037, zone#3038, des#3039, game_type#3040, stand#3041, p_throws#3042, home_team#3043, away_team#3044, type#3045, hit_location#3046, bb_type#3047, ... 70 more fields]\n",
                        "                                                      +- Project [_c0#3023, pitch_type#3024, game_date#3025, release_speed#3026, release_pos_x#3027, release_pos_z#3028, player_name#3029, batter#3030, pitcher#3031, events#3032, description#3033, spin_dir#3034, spin_rate_deprecated#3035, break_angle_deprecated#3036, break_length_deprecated#3037, zone#3038, des#3039, game_type#3040, stand#3041, p_throws#3042, home_team#3043, away_team#3044, type#3045, hit_location#3046, bb_type#3047, ... 69 more fields]\n",
                        "                                                         +- Filter ((((release_speed#3026 > cast(40 as double)) AND (release_speed#3026 < cast(110 as double))) AND isnotnull(pitcher#3031)) AND isnotnull(batter#3030))\n",
                        "                                                            +- Filter (((isnotnull(pitch_type#3024) AND isnotnull(release_speed#3026)) AND isnotnull(pitcher#3031)) AND isnotnull(batter#3030))\n",
                        "                                                               +- Union false, false\n",
                        "                                                                  :- Relation [_c0#3023,pitch_type#3024,game_date#3025,release_speed#3026,release_pos_x#3027,release_pos_z#3028,player_name#3029,batter#3030,pitcher#3031,events#3032,description#3033,spin_dir#3034,spin_rate_deprecated#3035,break_angle_deprecated#3036,break_length_deprecated#3037,zone#3038,des#3039,game_type#3040,stand#3041,p_throws#3042,home_team#3043,away_team#3044,type#3045,hit_location#3046,bb_type#3047,... 68 more fields] csv\n",
                        "                                                                  :- Relation [_c0#3116,pitch_type#3117,game_date#3118,release_speed#3119,release_pos_x#3120,release_pos_z#3121,player_name#3122,batter#3123,pitcher#3124,events#3125,description#3126,spin_dir#3127,spin_rate_deprecated#3128,break_angle_deprecated#3129,break_length_deprecated#3130,zone#3131,des#3132,game_type#3133,stand#3134,p_throws#3135,home_team#3136,away_team#3137,type#3138,hit_location#3139,bb_type#3140,... 68 more fields] csv\n",
                        "                                                                  :- Relation [_c0#3209,pitch_type#3210,game_date#3211,release_speed#3212,release_pos_x#3213,release_pos_z#3214,player_name#3215,batter#3216,pitcher#3217,events#3218,description#3219,spin_dir#3220,spin_rate_deprecated#3221,break_angle_deprecated#3222,break_length_deprecated#3223,zone#3224,des#3225,game_type#3226,stand#3227,p_throws#3228,home_team#3229,away_team#3230,type#3231,hit_location#3232,bb_type#3233,... 68 more fields] csv\n",
                        "                                                                  :- Relation [_c0#3302,pitch_type#3303,game_date#3304,release_speed#3305,release_pos_x#3306,release_pos_z#3307,player_name#3308,batter#3309,pitcher#3310,events#3311,description#3312,spin_dir#3313,spin_rate_deprecated#3314,break_angle_deprecated#3315,break_length_deprecated#3316,zone#3317,des#3318,game_type#3319,stand#3320,p_throws#3321,home_team#3322,away_team#3323,type#3324,hit_location#3325,bb_type#3326,... 68 more fields] csv\n",
                        "                                                                  +- Relation [_c0#3395,pitch_type#3396,game_date#3397,release_speed#3398,release_pos_x#3399,release_pos_z#3400,player_name#3401,batter#3402,pitcher#3403,events#3404,description#3405,spin_dir#3406,spin_rate_deprecated#3407,break_angle_deprecated#3408,break_length_deprecated#3409,zone#3410,des#3411,game_type#3412,stand#3413,p_throws#3414,home_team#3415,away_team#3416,type#3417,hit_location#3418,bb_type#3419,... 68 more fields] csv\n",
                        "\n",
                        "== Optimized Logical Plan ==\n",
                        "Sort [game_year_int#2489 ASC NULLS FIRST, count#3749L DESC NULLS LAST], true\n",
                        "+- Project [game_year_int#2489, pitch_type#18, count#3749L, round(((100.0 * cast(_w0#3755L as decimal(20,0))) / cast(_we0#3756L as decimal(20,0))), 2) AS pct#3750]\n",
                        "   +- Window [sum(_w0#3755L) windowspecdefinition(game_year_int#2489, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS _we0#3756L], [game_year_int#2489]\n",
                        "      +- Aggregate [game_year_int#2489, pitch_type#18], [game_year_int#2489, pitch_type#18, count(1) AS count#3749L, count(1) AS _w0#3755L]\n",
                        "         +- Union false, false\n",
                        "            :- Project [pitch_type#18, game_year#44 AS game_year_int#2489]\n",
                        "            :  +- Filter ((((isnotnull(pitch_type#18) AND isnotnull(release_speed#20)) AND isnotnull(pitcher#25)) AND isnotnull(batter#24)) AND (((release_speed#20 > 40.0) AND (release_speed#20 < 110.0)) AND (release_speed#20 > 50.0)))\n",
                        "            :     +- Relation [_c0#17,pitch_type#18,game_date#19,release_speed#20,release_pos_x#21,release_pos_z#22,player_name#23,batter#24,pitcher#25,events#26,description#27,spin_dir#28,spin_rate_deprecated#29,break_angle_deprecated#30,break_length_deprecated#31,zone#32,des#33,game_type#34,stand#35,p_throws#36,home_team#37,away_team#38,type#39,hit_location#40,bb_type#41,... 68 more fields] csv\n",
                        "            :- Project [pitch_type#225, game_year#251 AS game_year_int#3877]\n",
                        "            :  +- Filter ((((isnotnull(pitch_type#225) AND isnotnull(release_speed#227)) AND isnotnull(pitcher#232)) AND isnotnull(batter#231)) AND (((release_speed#227 > 40.0) AND (release_speed#227 < 110.0)) AND (release_speed#227 > 50.0)))\n",
                        "            :     +- Relation [_c0#224,pitch_type#225,game_date#226,release_speed#227,release_pos_x#228,release_pos_z#229,player_name#230,batter#231,pitcher#232,events#233,description#234,spin_dir#235,spin_rate_deprecated#236,break_angle_deprecated#237,break_length_deprecated#238,zone#239,des#240,game_type#241,stand#242,p_throws#243,home_team#244,away_team#245,type#246,hit_location#247,bb_type#248,... 68 more fields] csv\n",
                        "            :- Project [pitch_type#432, game_year#458 AS game_year_int#3878]\n",
                        "            :  +- Filter ((((isnotnull(pitch_type#432) AND isnotnull(release_speed#434)) AND isnotnull(pitcher#439)) AND isnotnull(batter#438)) AND (((release_speed#434 > 40.0) AND (release_speed#434 < 110.0)) AND (release_speed#434 > 50.0)))\n",
                        "            :     +- Relation [_c0#431,pitch_type#432,game_date#433,release_speed#434,release_pos_x#435,release_pos_z#436,player_name#437,batter#438,pitcher#439,events#440,description#441,spin_dir#442,spin_rate_deprecated#443,break_angle_deprecated#444,break_length_deprecated#445,zone#446,des#447,game_type#448,stand#449,p_throws#450,home_team#451,away_team#452,type#453,hit_location#454,bb_type#455,... 68 more fields] csv\n",
                        "            :- Project [pitch_type#639, game_year#665 AS game_year_int#3879]\n",
                        "            :  +- Filter ((((isnotnull(pitch_type#639) AND isnotnull(release_speed#641)) AND isnotnull(pitcher#646)) AND isnotnull(batter#645)) AND (((release_speed#641 > 40.0) AND (release_speed#641 < 110.0)) AND (release_speed#641 > 50.0)))\n",
                        "            :     +- Relation [_c0#638,pitch_type#639,game_date#640,release_speed#641,release_pos_x#642,release_pos_z#643,player_name#644,batter#645,pitcher#646,events#647,description#648,spin_dir#649,spin_rate_deprecated#650,break_angle_deprecated#651,break_length_deprecated#652,zone#653,des#654,game_type#655,stand#656,p_throws#657,home_team#658,away_team#659,type#660,hit_location#661,bb_type#662,... 68 more fields] csv\n",
                        "            +- Project [pitch_type#846, game_year#872 AS game_year_int#3880]\n",
                        "               +- Filter ((((isnotnull(pitch_type#846) AND isnotnull(release_speed#848)) AND isnotnull(pitcher#853)) AND isnotnull(batter#852)) AND (((release_speed#848 > 40.0) AND (release_speed#848 < 110.0)) AND (release_speed#848 > 50.0)))\n",
                        "                  +- Relation [_c0#845,pitch_type#846,game_date#847,release_speed#848,release_pos_x#849,release_pos_z#850,player_name#851,batter#852,pitcher#853,events#854,description#855,spin_dir#856,spin_rate_deprecated#857,break_angle_deprecated#858,break_length_deprecated#859,zone#860,des#861,game_type#862,stand#863,p_throws#864,home_team#865,away_team#866,type#867,hit_location#868,bb_type#869,... 68 more fields] csv\n",
                        "\n",
                        "== Physical Plan ==\n",
                        "AdaptiveSparkPlan isFinalPlan=false\n",
                        "+- Sort [game_year_int#2489 ASC NULLS FIRST, count#3749L DESC NULLS LAST], true, 0\n",
                        "   +- Exchange rangepartitioning(game_year_int#2489 ASC NULLS FIRST, count#3749L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=2990]\n",
                        "      +- Project [game_year_int#2489, pitch_type#18, count#3749L, round(((100.0 * cast(_w0#3755L as decimal(20,0))) / cast(_we0#3756L as decimal(20,0))), 2) AS pct#3750]\n",
                        "         +- Window [sum(_w0#3755L) windowspecdefinition(game_year_int#2489, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS _we0#3756L], [game_year_int#2489]\n",
                        "            +- Sort [game_year_int#2489 ASC NULLS FIRST], false, 0\n",
                        "               +- Exchange hashpartitioning(game_year_int#2489, 200), ENSURE_REQUIREMENTS, [plan_id=2985]\n",
                        "                  +- HashAggregate(keys=[game_year_int#2489, pitch_type#18], functions=[count(1)], output=[game_year_int#2489, pitch_type#18, count#3749L, _w0#3755L])\n",
                        "                     +- Exchange hashpartitioning(game_year_int#2489, pitch_type#18, 200), ENSURE_REQUIREMENTS, [plan_id=2982]\n",
                        "                        +- HashAggregate(keys=[game_year_int#2489, pitch_type#18], functions=[partial_count(1)], output=[game_year_int#2489, pitch_type#18, count#3766L])\n",
                        "                           +- Union\n",
                        "                              :- Project [pitch_type#18, game_year#44 AS game_year_int#2489]\n",
                        "                              :  +- Filter ((((((isnotnull(pitch_type#18) AND isnotnull(release_speed#20)) AND isnotnull(pitcher#25)) AND isnotnull(batter#24)) AND (release_speed#20 > 40.0)) AND (release_speed#20 < 110.0)) AND (release_speed#20 > 50.0))\n",
                        "                              :     +- FileScan csv [pitch_type#18,release_speed#20,batter#24,pitcher#25,game_year#44] Batched: false, DataFilters: [isnotnull(pitch_type#18), isnotnull(release_speed#20), isnotnull(pitcher#25), isnotnull(batter#2..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2018.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int,game_year:int>\n",
                        "                              :- Project [pitch_type#225, game_year#251 AS game_year_int#3877]\n",
                        "                              :  +- Filter ((((((isnotnull(pitch_type#225) AND isnotnull(release_speed#227)) AND isnotnull(pitcher#232)) AND isnotnull(batter#231)) AND (release_speed#227 > 40.0)) AND (release_speed#227 < 110.0)) AND (release_speed#227 > 50.0))\n",
                        "                              :     +- FileScan csv [pitch_type#225,release_speed#227,batter#231,pitcher#232,game_year#251] Batched: false, DataFilters: [isnotnull(pitch_type#225), isnotnull(release_speed#227), isnotnull(pitcher#232), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2019.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int,game_year:int>\n",
                        "                              :- Project [pitch_type#432, game_year#458 AS game_year_int#3878]\n",
                        "                              :  +- Filter ((((((isnotnull(pitch_type#432) AND isnotnull(release_speed#434)) AND isnotnull(pitcher#439)) AND isnotnull(batter#438)) AND (release_speed#434 > 40.0)) AND (release_speed#434 < 110.0)) AND (release_speed#434 > 50.0))\n",
                        "                              :     +- FileScan csv [pitch_type#432,release_speed#434,batter#438,pitcher#439,game_year#458] Batched: false, DataFilters: [isnotnull(pitch_type#432), isnotnull(release_speed#434), isnotnull(pitcher#439), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2020.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int,game_year:int>\n",
                        "                              :- Project [pitch_type#639, game_year#665 AS game_year_int#3879]\n",
                        "                              :  +- Filter ((((((isnotnull(pitch_type#639) AND isnotnull(release_speed#641)) AND isnotnull(pitcher#646)) AND isnotnull(batter#645)) AND (release_speed#641 > 40.0)) AND (release_speed#641 < 110.0)) AND (release_speed#641 > 50.0))\n",
                        "                              :     +- FileScan csv [pitch_type#639,release_speed#641,batter#645,pitcher#646,game_year#665] Batched: false, DataFilters: [isnotnull(pitch_type#639), isnotnull(release_speed#641), isnotnull(pitcher#646), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2021.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int,game_year:int>\n",
                        "                              +- Project [pitch_type#846, game_year#872 AS game_year_int#3880]\n",
                        "                                 +- Filter ((((((isnotnull(pitch_type#846) AND isnotnull(release_speed#848)) AND isnotnull(pitcher#853)) AND isnotnull(batter#852)) AND (release_speed#848 > 40.0)) AND (release_speed#848 < 110.0)) AND (release_speed#848 > 50.0))\n",
                        "                                    +- FileScan csv [pitch_type#846,release_speed#848,batter#852,pitcher#853,game_year#872] Batched: false, DataFilters: [isnotnull(pitch_type#846), isnotnull(release_speed#848), isnotnull(pitcher#853), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/statcast_2017.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int,game_year:int>\n",
                        "\n",
                        "\n",
                        "2. EXPLAIN FOR AGGREGATION (pitcher stats)\n",
                        "\n",
                        "== Parsed Logical Plan ==\n",
                        "'Filter '`>`('pitch_count, 100)\n",
                        "+- Aggregate [pitcher#25], [pitcher#25, count(1) AS pitch_count#2695L, avg(release_speed#20) AS avg_release_speed#2696, max(release_speed#20) AS max_release_speed#2697, sum(is_fastball#2484) AS fastball_count#2698L, sum(is_breaking#2485) AS breaking_count#2699L, sum(is_offspeed#2486) AS offspeed_count#2700L]\n",
                        "   +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 74 more fields]\n",
                        "      +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 73 more fields]\n",
                        "         +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 72 more fields]\n",
                        "            +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 72 more fields]\n",
                        "               +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 71 more fields]\n",
                        "                  +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 70 more fields]\n",
                        "                     +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 69 more fields]\n",
                        "                        +- Filter ((((release_speed#20 > cast(40 as double)) AND (release_speed#20 < cast(110 as double))) AND isnotnull(pitcher#25)) AND isnotnull(batter#24))\n",
                        "                           +- Filter (((isnotnull(pitch_type#18) AND isnotnull(release_speed#20)) AND isnotnull(pitcher#25)) AND isnotnull(batter#24))\n",
                        "                              +- Union false, false\n",
                        "                                 :- Relation [_c0#17,pitch_type#18,game_date#19,release_speed#20,release_pos_x#21,release_pos_z#22,player_name#23,batter#24,pitcher#25,events#26,description#27,spin_dir#28,spin_rate_deprecated#29,break_angle_deprecated#30,break_length_deprecated#31,zone#32,des#33,game_type#34,stand#35,p_throws#36,home_team#37,away_team#38,type#39,hit_location#40,bb_type#41,... 68 more fields] csv\n",
                        "                                 :- Relation [_c0#224,pitch_type#225,game_date#226,release_speed#227,release_pos_x#228,release_pos_z#229,player_name#230,batter#231,pitcher#232,events#233,description#234,spin_dir#235,spin_rate_deprecated#236,break_angle_deprecated#237,break_length_deprecated#238,zone#239,des#240,game_type#241,stand#242,p_throws#243,home_team#244,away_team#245,type#246,hit_location#247,bb_type#248,... 68 more fields] csv\n",
                        "                                 :- Relation [_c0#431,pitch_type#432,game_date#433,release_speed#434,release_pos_x#435,release_pos_z#436,player_name#437,batter#438,pitcher#439,events#440,description#441,spin_dir#442,spin_rate_deprecated#443,break_angle_deprecated#444,break_length_deprecated#445,zone#446,des#447,game_type#448,stand#449,p_throws#450,home_team#451,away_team#452,type#453,hit_location#454,bb_type#455,... 68 more fields] csv\n",
                        "                                 :- Relation [_c0#638,pitch_type#639,game_date#640,release_speed#641,release_pos_x#642,release_pos_z#643,player_name#644,batter#645,pitcher#646,events#647,description#648,spin_dir#649,spin_rate_deprecated#650,break_angle_deprecated#651,break_length_deprecated#652,zone#653,des#654,game_type#655,stand#656,p_throws#657,home_team#658,away_team#659,type#660,hit_location#661,bb_type#662,... 68 more fields] csv\n",
                        "                                 +- Relation [_c0#845,pitch_type#846,game_date#847,release_speed#848,release_pos_x#849,release_pos_z#850,player_name#851,batter#852,pitcher#853,events#854,description#855,spin_dir#856,spin_rate_deprecated#857,break_angle_deprecated#858,break_length_deprecated#859,zone#860,des#861,game_type#862,stand#863,p_throws#864,home_team#865,away_team#866,type#867,hit_location#868,bb_type#869,... 68 more fields] csv\n",
                        "\n",
                        "== Analyzed Logical Plan ==\n",
                        "pitcher: int, pitch_count: bigint, avg_release_speed: double, max_release_speed: double, fastball_count: bigint, breaking_count: bigint, offspeed_count: bigint\n",
                        "Filter (pitch_count#2695L > cast(100 as bigint))\n",
                        "+- Aggregate [pitcher#25], [pitcher#25, count(1) AS pitch_count#2695L, avg(release_speed#20) AS avg_release_speed#2696, max(release_speed#20) AS max_release_speed#2697, sum(is_fastball#2484) AS fastball_count#2698L, sum(is_breaking#2485) AS breaking_count#2699L, sum(is_offspeed#2486) AS offspeed_count#2700L]\n",
                        "   +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 74 more fields]\n",
                        "      +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 73 more fields]\n",
                        "         +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 72 more fields]\n",
                        "            +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 72 more fields]\n",
                        "               +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 71 more fields]\n",
                        "                  +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 70 more fields]\n",
                        "                     +- Project [_c0#17, pitch_type#18, game_date#19, release_speed#20, release_pos_x#21, release_pos_z#22, player_name#23, batter#24, pitcher#25, events#26, description#27, spin_dir#28, spin_rate_deprecated#29, break_angle_deprecated#30, break_length_deprecated#31, zone#32, des#33, game_type#34, stand#35, p_throws#36, home_team#37, away_team#38, type#39, hit_location#40, bb_type#41, ... 69 more fields]\n",
                        "                        +- Filter ((((release_speed#20 > cast(40 as double)) AND (release_speed#20 < cast(110 as double))) AND isnotnull(pitcher#25)) AND isnotnull(batter#24))\n",
                        "                           +- Filter (((isnotnull(pitch_type#18) AND isnotnull(release_speed#20)) AND isnotnull(pitcher#25)) AND isnotnull(batter#24))\n",
                        "                              +- Union false, false\n",
                        "                                 :- Relation [_c0#17,pitch_type#18,game_date#19,release_speed#20,release_pos_x#21,release_pos_z#22,player_name#23,batter#24,pitcher#25,events#26,description#27,spin_dir#28,spin_rate_deprecated#29,break_angle_deprecated#30,break_length_deprecated#31,zone#32,des#33,game_type#34,stand#35,p_throws#36,home_team#37,away_team#38,type#39,hit_location#40,bb_type#41,... 68 more fields] csv\n",
                        "                                 :- Relation [_c0#224,pitch_type#225,game_date#226,release_speed#227,release_pos_x#228,release_pos_z#229,player_name#230,batter#231,pitcher#232,events#233,description#234,spin_dir#235,spin_rate_deprecated#236,break_angle_deprecated#237,break_length_deprecated#238,zone#239,des#240,game_type#241,stand#242,p_throws#243,home_team#244,away_team#245,type#246,hit_location#247,bb_type#248,... 68 more fields] csv\n",
                        "                                 :- Relation [_c0#431,pitch_type#432,game_date#433,release_speed#434,release_pos_x#435,release_pos_z#436,player_name#437,batter#438,pitcher#439,events#440,description#441,spin_dir#442,spin_rate_deprecated#443,break_angle_deprecated#444,break_length_deprecated#445,zone#446,des#447,game_type#448,stand#449,p_throws#450,home_team#451,away_team#452,type#453,hit_location#454,bb_type#455,... 68 more fields] csv\n",
                        "                                 :- Relation [_c0#638,pitch_type#639,game_date#640,release_speed#641,release_pos_x#642,release_pos_z#643,player_name#644,batter#645,pitcher#646,events#647,description#648,spin_dir#649,spin_rate_deprecated#650,break_angle_deprecated#651,break_length_deprecated#652,zone#653,des#654,game_type#655,stand#656,p_throws#657,home_team#658,away_team#659,type#660,hit_location#661,bb_type#662,... 68 more fields] csv\n",
                        "                                 +- Relation [_c0#845,pitch_type#846,game_date#847,release_speed#848,release_pos_x#849,release_pos_z#850,player_name#851,batter#852,pitcher#853,events#854,description#855,spin_dir#856,spin_rate_deprecated#857,break_angle_deprecated#858,break_length_deprecated#859,zone#860,des#861,game_type#862,stand#863,p_throws#864,home_team#865,away_team#866,type#867,hit_location#868,bb_type#869,... 68 more fields] csv\n",
                        "\n",
                        "== Optimized Logical Plan ==\n",
                        "Filter (pitch_count#2695L > 100)\n",
                        "+- Aggregate [pitcher#25], [pitcher#25, count(1) AS pitch_count#2695L, avg(release_speed#20) AS avg_release_speed#2696, max(release_speed#20) AS max_release_speed#2697, sum(is_fastball#2484) AS fastball_count#2698L, sum(is_breaking#2485) AS breaking_count#2699L, sum(is_offspeed#2486) AS offspeed_count#2700L]\n",
                        "   +- Union false, false\n",
                        "      :- Project [release_speed#20, pitcher#25, CASE WHEN pitch_type#18 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#2484, CASE WHEN pitch_type#18 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#2485, CASE WHEN pitch_type#18 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#2486]\n",
                        "      :  +- Filter (((((isnotnull(pitch_type#18) AND isnotnull(release_speed#20)) AND isnotnull(pitcher#25)) AND isnotnull(batter#24)) AND (release_speed#20 > 40.0)) AND (release_speed#20 < 110.0))\n",
                        "      :     +- Relation [_c0#17,pitch_type#18,game_date#19,release_speed#20,release_pos_x#21,release_pos_z#22,player_name#23,batter#24,pitcher#25,events#26,description#27,spin_dir#28,spin_rate_deprecated#29,break_angle_deprecated#30,break_length_deprecated#31,zone#32,des#33,game_type#34,stand#35,p_throws#36,home_team#37,away_team#38,type#39,hit_location#40,bb_type#41,... 68 more fields] csv\n",
                        "      :- Project [release_speed#227, pitcher#232, CASE WHEN pitch_type#225 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#3881, CASE WHEN pitch_type#225 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#3882, CASE WHEN pitch_type#225 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#3883]\n",
                        "      :  +- Filter (((((isnotnull(pitch_type#225) AND isnotnull(release_speed#227)) AND isnotnull(pitcher#232)) AND isnotnull(batter#231)) AND (release_speed#227 > 40.0)) AND (release_speed#227 < 110.0))\n",
                        "      :     +- Relation [_c0#224,pitch_type#225,game_date#226,release_speed#227,release_pos_x#228,release_pos_z#229,player_name#230,batter#231,pitcher#232,events#233,description#234,spin_dir#235,spin_rate_deprecated#236,break_angle_deprecated#237,break_length_deprecated#238,zone#239,des#240,game_type#241,stand#242,p_throws#243,home_team#244,away_team#245,type#246,hit_location#247,bb_type#248,... 68 more fields] csv\n",
                        "      :- Project [release_speed#434, pitcher#439, CASE WHEN pitch_type#432 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#3884, CASE WHEN pitch_type#432 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#3885, CASE WHEN pitch_type#432 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#3886]\n",
                        "      :  +- Filter (((((isnotnull(pitch_type#432) AND isnotnull(release_speed#434)) AND isnotnull(pitcher#439)) AND isnotnull(batter#438)) AND (release_speed#434 > 40.0)) AND (release_speed#434 < 110.0))\n",
                        "      :     +- Relation [_c0#431,pitch_type#432,game_date#433,release_speed#434,release_pos_x#435,release_pos_z#436,player_name#437,batter#438,pitcher#439,events#440,description#441,spin_dir#442,spin_rate_deprecated#443,break_angle_deprecated#444,break_length_deprecated#445,zone#446,des#447,game_type#448,stand#449,p_throws#450,home_team#451,away_team#452,type#453,hit_location#454,bb_type#455,... 68 more fields] csv\n",
                        "      :- Project [release_speed#641, pitcher#646, CASE WHEN pitch_type#639 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#3887, CASE WHEN pitch_type#639 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#3888, CASE WHEN pitch_type#639 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#3889]\n",
                        "      :  +- Filter (((((isnotnull(pitch_type#639) AND isnotnull(release_speed#641)) AND isnotnull(pitcher#646)) AND isnotnull(batter#645)) AND (release_speed#641 > 40.0)) AND (release_speed#641 < 110.0))\n",
                        "      :     +- Relation [_c0#638,pitch_type#639,game_date#640,release_speed#641,release_pos_x#642,release_pos_z#643,player_name#644,batter#645,pitcher#646,events#647,description#648,spin_dir#649,spin_rate_deprecated#650,break_angle_deprecated#651,break_length_deprecated#652,zone#653,des#654,game_type#655,stand#656,p_throws#657,home_team#658,away_team#659,type#660,hit_location#661,bb_type#662,... 68 more fields] csv\n",
                        "      +- Project [release_speed#848, pitcher#853, CASE WHEN pitch_type#846 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#3890, CASE WHEN pitch_type#846 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#3891, CASE WHEN pitch_type#846 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#3892]\n",
                        "         +- Filter (((((isnotnull(pitch_type#846) AND isnotnull(release_speed#848)) AND isnotnull(pitcher#853)) AND isnotnull(batter#852)) AND (release_speed#848 > 40.0)) AND (release_speed#848 < 110.0))\n",
                        "            +- Relation [_c0#845,pitch_type#846,game_date#847,release_speed#848,release_pos_x#849,release_pos_z#850,player_name#851,batter#852,pitcher#853,events#854,description#855,spin_dir#856,spin_rate_deprecated#857,break_angle_deprecated#858,break_length_deprecated#859,zone#860,des#861,game_type#862,stand#863,p_throws#864,home_team#865,away_team#866,type#867,hit_location#868,bb_type#869,... 68 more fields] csv\n",
                        "\n",
                        "== Physical Plan ==\n",
                        "AdaptiveSparkPlan isFinalPlan=false\n",
                        "+- Filter (pitch_count#2695L > 100)\n",
                        "   +- HashAggregate(keys=[pitcher#25], functions=[count(1), avg(release_speed#20), max(release_speed#20), sum(is_fastball#2484), sum(is_breaking#2485), sum(is_offspeed#2486)], output=[pitcher#25, pitch_count#2695L, avg_release_speed#2696, max_release_speed#2697, fastball_count#2698L, breaking_count#2699L, offspeed_count#2700L])\n",
                        "      +- Exchange hashpartitioning(pitcher#25, 200), ENSURE_REQUIREMENTS, [plan_id=3047]\n",
                        "         +- HashAggregate(keys=[pitcher#25], functions=[partial_count(1), partial_avg(release_speed#20), partial_max(release_speed#20), partial_sum(is_fastball#2484), partial_sum(is_breaking#2485), partial_sum(is_offspeed#2486)], output=[pitcher#25, count#2818L, sum#2864, count#2865L, max#2866, sum#2867L, sum#2868L, sum#2869L])\n",
                        "            +- Union\n",
                        "               :- Project [release_speed#20, pitcher#25, CASE WHEN pitch_type#18 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#2484, CASE WHEN pitch_type#18 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#2485, CASE WHEN pitch_type#18 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#2486]\n",
                        "               :  +- Filter (((((isnotnull(pitch_type#18) AND isnotnull(release_speed#20)) AND isnotnull(pitcher#25)) AND isnotnull(batter#24)) AND (release_speed#20 > 40.0)) AND (release_speed#20 < 110.0))\n",
                        "               :     +- FileScan csv [pitch_type#18,release_speed#20,batter#24,pitcher#25] Batched: false, DataFilters: [isnotnull(pitch_type#18), isnotnull(release_speed#20), isnotnull(pitcher#25), isnotnull(batter#2..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2018.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        "               :- Project [release_speed#227, pitcher#232, CASE WHEN pitch_type#225 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#3881, CASE WHEN pitch_type#225 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#3882, CASE WHEN pitch_type#225 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#3883]\n",
                        "               :  +- Filter (((((isnotnull(pitch_type#225) AND isnotnull(release_speed#227)) AND isnotnull(pitcher#232)) AND isnotnull(batter#231)) AND (release_speed#227 > 40.0)) AND (release_speed#227 < 110.0))\n",
                        "               :     +- FileScan csv [pitch_type#225,release_speed#227,batter#231,pitcher#232] Batched: false, DataFilters: [isnotnull(pitch_type#225), isnotnull(release_speed#227), isnotnull(pitcher#232), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2019.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        "               :- Project [release_speed#434, pitcher#439, CASE WHEN pitch_type#432 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#3884, CASE WHEN pitch_type#432 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#3885, CASE WHEN pitch_type#432 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#3886]\n",
                        "               :  +- Filter (((((isnotnull(pitch_type#432) AND isnotnull(release_speed#434)) AND isnotnull(pitcher#439)) AND isnotnull(batter#438)) AND (release_speed#434 > 40.0)) AND (release_speed#434 < 110.0))\n",
                        "               :     +- FileScan csv [pitch_type#432,release_speed#434,batter#438,pitcher#439] Batched: false, DataFilters: [isnotnull(pitch_type#432), isnotnull(release_speed#434), isnotnull(pitcher#439), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2020.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        "               :- Project [release_speed#641, pitcher#646, CASE WHEN pitch_type#639 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#3887, CASE WHEN pitch_type#639 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#3888, CASE WHEN pitch_type#639 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#3889]\n",
                        "               :  +- Filter (((((isnotnull(pitch_type#639) AND isnotnull(release_speed#641)) AND isnotnull(pitcher#646)) AND isnotnull(batter#645)) AND (release_speed#641 > 40.0)) AND (release_speed#641 < 110.0))\n",
                        "               :     +- FileScan csv [pitch_type#639,release_speed#641,batter#645,pitcher#646] Batched: false, DataFilters: [isnotnull(pitch_type#639), isnotnull(release_speed#641), isnotnull(pitcher#646), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2021.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        "               +- Project [release_speed#848, pitcher#853, CASE WHEN pitch_type#846 IN (FF,FT,FC,FS) THEN 1 ELSE 0 END AS is_fastball#3890, CASE WHEN pitch_type#846 IN (CU,SL,KC,EP) THEN 1 ELSE 0 END AS is_breaking#3891, CASE WHEN pitch_type#846 IN (CH,SC) THEN 1 ELSE 0 END AS is_offspeed#3892]\n",
                        "                  +- Filter (((((isnotnull(pitch_type#846) AND isnotnull(release_speed#848)) AND isnotnull(pitcher#853)) AND isnotnull(batter#852)) AND (release_speed#848 > 40.0)) AND (release_speed#848 < 110.0))\n",
                        "                     +- FileScan csv [pitch_type#846,release_speed#848,batter#852,pitcher#853] Batched: false, DataFilters: [isnotnull(pitch_type#846), isnotnull(release_speed#848), isnotnull(pitcher#853), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/statcast_2017.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        "\n",
                        "\n",
                        "\n",
                        "=== PERFORMANCE ANALYSIS SUMMARY ===\n",
                        "\n",
                        "## Optimization Strategies Applied:\n",
                        "\n",
                        "### 1. Filter Pushdown (Early Filtering)\n",
                        "- Filters on 'pitch_type', 'release_speed' were applied BEFORE groupBy operations\n",
                        "- This allows Spark to scan only relevant data blocks, reducing I/O and memory usage\n",
                        "- Example: WHERE release_speed > 50 is evaluated at the scan level\n",
                        "\n",
                        "### 2. Column Pruning\n",
                        "- Only selected necessary columns in SELECT clauses (pitcher, pitch_count, avg_release_speed, etc.)\n",
                        "- Unused columns are pruned from the execution plan\n",
                        "- Reduces data shuffled between stages\n",
                        "\n",
                        "### 3. Partitioning Strategy\n",
                        "- Dataset has 'game_year_int' which is used in aggregations\n",
                        "- Spark's Adaptive Query Execution (AQE) enabled: detects join/shuffle sizes and optimizes dynamically\n",
                        "- SQL queries partition by game_year_int to enable parallel processing per year\n",
                        "\n",
                        "### 4. Avoiding Unnecessary Shuffles\n",
                        "- Pitcher stats aggregation groups on single column 'pitcher' (efficient local grouping)\n",
                        "- Joins use column broadcast for small lookup tables where applicable\n",
                        "- Window function (OVER clause) in Query 2 uses PARTITION BY game_year_int to localize computation\n",
                        "\n",
                        "### 5. Write Optimization\n",
                        "- Used .coalesce(1) before CSV write to reduce file count and avoid small file fragmentation\n",
                        "- Alternative: .partitionBy('game_year_int') could be used if reading partitioned data repeatedly\n",
                        "\n",
                        "## Performance Bottlenecks Identified:\n",
                        "\n",
                        "1. **CSV Read Overhead**: Reading 5 CSV files (361MB+ total) requires parsing of string data\n",
                        "   - Mitigation: Pre-convert to Parquet in production; use binary format with schema inference cached\n",
                        "\n",
                        "2. **Shuffle on Pitch Type Distribution**: The window function in Query 2 causes a shuffle by game_year_int\n",
                        "   - Expected since we need per-year percentages\n",
                        "   - Mitigation: Dataset is grouped into years naturally; shuffle size is manageable\n",
                        "\n",
                        "3. **Memory Usage for Large Aggregations**: Aggregating on pitcher (100+ unique pitchers) + pitch_type (10+ types)\n",
                        "   - Mitigation: Applied filters (pitch_count > 100) to reduce result set size\n",
                        "\n",
                        "## Spark Optimizations Observed:\n",
                        "\n",
                        "- **Adaptive Query Execution (AQE)**: Enabled with spark.sql.adaptive.enabled=true\n",
                        "  - Dynamically adjusts join strategy based on runtime statistics\n",
                        "  - Coalesces shuffle partitions if intermediate results are small\n",
                        "\n",
                        "- **Column Pruning**: Unused columns automatically removed from execution plans\n",
                        "\n",
                        "- **Predicate Pushdown**: Filter conditions pushed down to CSV scan layer where possible\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# BLOCK 3: Performance Analysis with .explain() and Optimization Review\n",
                "# ========================================================================\n",
                "\n",
                "print(\"\\n=== PERFORMANCE ANALYSIS ===\")\n",
                "print(\"\\n1. PHYSICAL EXECUTION PLAN (from Query 2)\\n\")\n",
                "print(\"Explaining the SQL query 2 (pitch type distribution):\")\n",
                "result2.explain(extended=True)\n",
                "\n",
                "print(\"\\n2. EXPLAIN FOR AGGREGATION (pitcher stats)\\n\")\n",
                "pitcher_stats.explain(extended=True)\n",
                "\n",
                "print(\"\"\"\n",
                "\\n=== PERFORMANCE ANALYSIS SUMMARY ===\n",
                "\n",
                "## Optimization Strategies Applied:\n",
                "\n",
                "### 1. Filter Pushdown (Early Filtering)\n",
                "- Filters on 'pitch_type', 'release_speed' were applied BEFORE groupBy operations\n",
                "- This allows Spark to scan only relevant data blocks, reducing I/O and memory usage\n",
                "- Example: WHERE release_speed > 50 is evaluated at the scan level\n",
                "\n",
                "### 2. Column Pruning\n",
                "- Only selected necessary columns in SELECT clauses (pitcher, pitch_count, avg_release_speed, etc.)\n",
                "- Unused columns are pruned from the execution plan\n",
                "- Reduces data shuffled between stages\n",
                "\n",
                "### 3. Partitioning Strategy\n",
                "- Dataset has 'game_year_int' which is used in aggregations\n",
                "- Spark's Adaptive Query Execution (AQE) enabled: detects join/shuffle sizes and optimizes dynamically\n",
                "- SQL queries partition by game_year_int to enable parallel processing per year\n",
                "\n",
                "### 4. Avoiding Unnecessary Shuffles\n",
                "- Pitcher stats aggregation groups on single column 'pitcher' (efficient local grouping)\n",
                "- Joins use column broadcast for small lookup tables where applicable\n",
                "- Window function (OVER clause) in Query 2 uses PARTITION BY game_year_int to localize computation\n",
                "\n",
                "### 5. Write Optimization\n",
                "- Used .coalesce(1) before CSV write to reduce file count and avoid small file fragmentation\n",
                "- Alternative: .partitionBy('game_year_int') could be used if reading partitioned data repeatedly\n",
                "\n",
                "## Performance Bottlenecks Identified:\n",
                "\n",
                "1. **CSV Read Overhead**: Reading 5 CSV files (361MB+ total) requires parsing of string data\n",
                "   - Mitigation: Pre-convert to Parquet in production; use binary format with schema inference cached\n",
                "\n",
                "2. **Shuffle on Pitch Type Distribution**: The window function in Query 2 causes a shuffle by game_year_int\n",
                "   - Expected since we need per-year percentages\n",
                "   - Mitigation: Dataset is grouped into years naturally; shuffle size is manageable\n",
                "\n",
                "3. **Memory Usage for Large Aggregations**: Aggregating on pitcher (100+ unique pitchers) + pitch_type (10+ types)\n",
                "   - Mitigation: Applied filters (pitch_count > 100) to reduce result set size\n",
                "\n",
                "## Spark Optimizations Observed:\n",
                "\n",
                "- **Adaptive Query Execution (AQE)**: Enabled with spark.sql.adaptive.enabled=true\n",
                "  - Dynamically adjusts join strategy based on runtime statistics\n",
                "  - Coalesces shuffle partitions if intermediate results are small\n",
                "\n",
                "- **Column Pruning**: Unused columns automatically removed from execution plans\n",
                "\n",
                "- **Predicate Pushdown**: Filter conditions pushed down to CSV scan layer where possible\n",
                "\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "ac551374",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== CACHING OPTIMIZATION BENCHMARK ===\n",
                        "\n",
                        "1. Running aggregation WITHOUT cache:\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  First run (no cache): 1.373s\n",
                        "  Second run (no cache): 0.019s\n",
                        "  Average: 0.696s\n",
                        "\n",
                        "2. Running same aggregation WITH cache:\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Cache materialization: 4.064s\n",
                        "  First run (with cache): 0.543s\n",
                        "  Second run (with cache): 0.029s\n",
                        "  Average: 0.286s\n",
                        "\n",
                        "3. IMPROVEMENT:\n",
                        "  Without cache avg: 0.696s\n",
                        "  With cache avg: 0.286s\n",
                        "  Improvement: 58.8% faster with cache\n",
                        "  Speedup factor: 2.43x\n",
                        "\n",
                        "Conclusion: Caching beneficial when repeating aggregations/joins on same data.\n",
                        "Use .cache() or .persist() for DataFrames reused in multiple actions.\n",
                        "  First run (with cache): 0.543s\n",
                        "  Second run (with cache): 0.029s\n",
                        "  Average: 0.286s\n",
                        "\n",
                        "3. IMPROVEMENT:\n",
                        "  Without cache avg: 0.696s\n",
                        "  With cache avg: 0.286s\n",
                        "  Improvement: 58.8% faster with cache\n",
                        "  Speedup factor: 2.43x\n",
                        "\n",
                        "Conclusion: Caching beneficial when repeating aggregations/joins on same data.\n",
                        "Use .cache() or .persist() for DataFrames reused in multiple actions.\n"
                    ]
                }
            ],
            "source": [
                "# BLOCK 4 (BONUS): Caching Optimization\n",
                "# =======================================\n",
                "# Demonstrate how .cache() improves performance for repeated actions\n",
                "\n",
                "print(\"\\n=== CACHING OPTIMIZATION BENCHMARK ===\")\n",
                "\n",
                "# Create a non-trivial DataFrame for benchmarking\n",
                "test_df = df_with_pitcher_batter.filter(\n",
                "    (col(\"release_speed\") > 60) &\n",
                "    (col(\"game_year_int\") >= 2019)\n",
                ").select(\n",
                "    \"pitcher\", \"batter\", \"release_speed\", \"pitch_type\", \n",
                "    \"is_fastball\", \"is_breaking\", \"pitcher_avg_speed\"\n",
                ")\n",
                "\n",
                "spark.catalog.clearCache()\n",
                "\n",
                "# Benchmark WITHOUT caching: run the same aggregation twice\n",
                "print(\"\\n1. Running aggregation WITHOUT cache:\")\n",
                "agg_query = test_df.groupBy(\"pitch_type\").agg(\n",
                "    count(\"*\").alias(\"count\"),\n",
                "    avg(\"release_speed\").alias(\"avg_speed\")\n",
                ")\n",
                "\n",
                "start_no_cache = time.time()\n",
                "result_no_cache_1 = agg_query.collect()\n",
                "time_no_cache_1 = time.time() - start_no_cache\n",
                "print(f\"  First run (no cache): {time_no_cache_1:.3f}s\")\n",
                "\n",
                "start_no_cache = time.time()\n",
                "result_no_cache_2 = agg_query.collect()\n",
                "time_no_cache_2 = time.time() - start_no_cache\n",
                "print(f\"  Second run (no cache): {time_no_cache_2:.3f}s\")\n",
                "avg_no_cache = (time_no_cache_1 + time_no_cache_2) / 2\n",
                "print(f\"  Average: {avg_no_cache:.3f}s\")\n",
                "\n",
                "# Benchmark WITH caching\n",
                "print(\"\\n2. Running same aggregation WITH cache:\")\n",
                "spark.catalog.clearCache()\n",
                "\n",
                "# Cache the test DataFrame\n",
                "test_df.persist(StorageLevel.MEMORY_AND_DISK)\n",
                "start_materialize = time.time()\n",
                "_ = test_df.count()  # Materialize the cache\n",
                "time_materialize = time.time() - start_materialize\n",
                "print(f\"  Cache materialization: {time_materialize:.3f}s\")\n",
                "\n",
                "# Run aggregation on cached data\n",
                "agg_cached = test_df.groupBy(\"pitch_type\").agg(\n",
                "    count(\"*\").alias(\"count\"),\n",
                "    avg(\"release_speed\").alias(\"avg_speed\")\n",
                ")\n",
                "\n",
                "start_cache = time.time()\n",
                "result_cache_1 = agg_cached.collect()\n",
                "time_cache_1 = time.time() - start_cache\n",
                "print(f\"  First run (with cache): {time_cache_1:.3f}s\")\n",
                "\n",
                "start_cache = time.time()\n",
                "result_cache_2 = agg_cached.collect()\n",
                "time_cache_2 = time.time() - start_cache\n",
                "print(f\"  Second run (with cache): {time_cache_2:.3f}s\")\n",
                "avg_cache = (time_cache_1 + time_cache_2) / 2\n",
                "print(f\"  Average: {avg_cache:.3f}s\")\n",
                "\n",
                "# Clean up cache\n",
                "test_df.unpersist()\n",
                "spark.catalog.clearCache()\n",
                "\n",
                "print(f\"\\n3. IMPROVEMENT:\")\n",
                "if avg_cache > 0:\n",
                "    improvement = (avg_no_cache - avg_cache) / avg_no_cache * 100\n",
                "    print(f\"  Without cache avg: {avg_no_cache:.3f}s\")\n",
                "    print(f\"  With cache avg: {avg_cache:.3f}s\")\n",
                "    print(f\"  Improvement: {improvement:.1f}% faster with cache\")\n",
                "    if avg_cache < avg_no_cache:\n",
                "        print(f\"  Speedup factor: {avg_no_cache / avg_cache:.2f}x\")\n",
                "\n",
                "print(\"\\nConclusion: Caching beneficial when repeating aggregations/joins on same data.\")\n",
                "print(\"Use .cache() or .persist() for DataFrames reused in multiple actions.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "b71232c5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== ACTIONS VS TRANSFORMATIONS DEMONSTRATION ===\n",
                        "\n",
                        "1. TRANSFORMATIONS (Lazy - No execution):\n",
                        "--------------------------------------------------\n",
                        "Building transformation pipeline...\n",
                        "  1. Filter speed > 85: Created (no computation)\n",
                        "  2. Filter pitch type: Created (no computation)\n",
                        "  3. Add speed_category column: Created (no computation)\n",
                        "  4. Select columns: Created (no computation)\n",
                        "\n",
                        "Execution Plan (no compute yet):\n",
                        "== Physical Plan ==\n",
                        "Union\n",
                        ":- *(1) Project [pitcher#25, release_speed#20, pitch_type#18, CASE WHEN (release_speed#20 > 95.0) THEN Very Fast ELSE Fast END AS speed_category#4419]\n",
                        ":  +- *(1) Filter (((((((isnotnull(pitch_type#18) AND isnotnull(release_speed#20)) AND isnotnull(pitcher#25)) AND isnotnull(batter#24)) AND (release_speed#20 > 40.0)) AND (release_speed#20 < 110.0)) AND (release_speed#20 > 85.0)) AND pitch_type#18 IN (FF,SL,CU))\n",
                        ":     +- FileScan csv [pitch_type#18,release_speed#20,batter#24,pitcher#25] Batched: false, DataFilters: [isnotnull(pitch_type#18), isnotnull(release_speed#20), isnotnull(pitcher#25), isnotnull(batter#2..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2018.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        ":- *(2) Project [pitcher#232, release_speed#227, pitch_type#225, CASE WHEN (release_speed#227 > 95.0) THEN Very Fast ELSE Fast END AS speed_category#4420]\n",
                        ":  +- *(2) Filter (((((((isnotnull(pitch_type#225) AND isnotnull(release_speed#227)) AND isnotnull(pitcher#232)) AND isnotnull(batter#231)) AND (release_speed#227 > 40.0)) AND (release_speed#227 < 110.0)) AND (release_speed#227 > 85.0)) AND pitch_type#225 IN (FF,SL,CU))\n",
                        ":     +- FileScan csv [pitch_type#225,release_speed#227,batter#231,pitcher#232] Batched: false, DataFilters: [isnotnull(pitch_type#225), isnotnull(release_speed#227), isnotnull(pitcher#232), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2019.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        ":- *(3) Project [pitcher#439, release_speed#434, pitch_type#432, CASE WHEN (release_speed#434 > 95.0) THEN Very Fast ELSE Fast END AS speed_category#4421]\n",
                        ":  +- *(3) Filter (((((((isnotnull(pitch_type#432) AND isnotnull(release_speed#434)) AND isnotnull(pitcher#439)) AND isnotnull(batter#438)) AND (release_speed#434 > 40.0)) AND (release_speed#434 < 110.0)) AND (release_speed#434 > 85.0)) AND pitch_type#432 IN (FF,SL,CU))\n",
                        ":     +- FileScan csv [pitch_type#432,release_speed#434,batter#438,pitcher#439] Batched: false, DataFilters: [isnotnull(pitch_type#432), isnotnull(release_speed#434), isnotnull(pitcher#439), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2020.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        ":- *(4) Project [pitcher#646, release_speed#641, pitch_type#639, CASE WHEN (release_speed#641 > 95.0) THEN Very Fast ELSE Fast END AS speed_category#4422]\n",
                        ":  +- *(4) Filter (((((((isnotnull(pitch_type#639) AND isnotnull(release_speed#641)) AND isnotnull(pitcher#646)) AND isnotnull(batter#645)) AND (release_speed#641 > 40.0)) AND (release_speed#641 < 110.0)) AND (release_speed#641 > 85.0)) AND pitch_type#639 IN (FF,SL,CU))\n",
                        ":     +- FileScan csv [pitch_type#639,release_speed#641,batter#645,pitcher#646] Batched: false, DataFilters: [isnotnull(pitch_type#639), isnotnull(release_speed#641), isnotnull(pitcher#646), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/Statcast_2021.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        "+- *(5) Project [pitcher#853, release_speed#848, pitch_type#846, CASE WHEN (release_speed#848 > 95.0) THEN Very Fast ELSE Fast END AS speed_category#4423]\n",
                        "   +- *(5) Filter (((((((isnotnull(pitch_type#846) AND isnotnull(release_speed#848)) AND isnotnull(pitcher#853)) AND isnotnull(batter#852)) AND (release_speed#848 > 40.0)) AND (release_speed#848 < 110.0)) AND (release_speed#848 > 85.0)) AND pitch_type#846 IN (FF,SL,CU))\n",
                        "      +- FileScan csv [pitch_type#846,release_speed#848,batter#852,pitcher#853] Batched: false, DataFilters: [isnotnull(pitch_type#846), isnotnull(release_speed#848), isnotnull(pitcher#853), isnotnull(batte..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/workspaces/IDS706-Mini-Assignment-PySpark/data/statcast_2017.csv], PartitionFilters: [], PushedFilters: [IsNotNull(pitch_type), IsNotNull(release_speed), IsNotNull(pitcher), IsNotNull(batter), GreaterT..., ReadSchema: struct<pitch_type:string,release_speed:double,batter:int,pitcher:int>\n",
                        "\n",
                        "\n",
                        "\n",
                        "2. ACTIONS (Eager - Force execution):\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "Executing ACTION: .count()\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Result: 1,359,972 rows\n",
                        "  Time: 1.448s\n",
                        "\n",
                        "Executing ACTION: .show(3)\n",
                        "+-------+-------------+----------+--------------+\n",
                        "|pitcher|release_speed|pitch_type|speed_category|\n",
                        "+-------+-------------+----------+--------------+\n",
                        "|459429 |94.0         |FF        |Fast          |\n",
                        "|459429 |95.0         |FF        |Fast          |\n",
                        "|459429 |94.8         |FF        |Fast          |\n",
                        "+-------+-------------+----------+--------------+\n",
                        "only showing top 3 rows\n",
                        "  Time to show: 0.102s\n",
                        "\n",
                        "Executing ACTION: .collect() (small sample)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[Stage 110:========================================>             (45 + 12) / 60]\r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Collected 1398 rows back to driver\n",
                        "  Time: 1.398s\n",
                        "\n",
                        "\n",
                        "3. KEY INSIGHTS:\n",
                        "   - Transformations (filter, withColumn, select) are LAZY: they don't execute immediately\n",
                        "   - They only execute when an ACTION is called (count, show, collect, write, etc.)\n",
                        "   - Spark can optimize the entire pipeline by seeing all transformations before execution\n",
                        "   - This enables query optimization (filter pushdown, column pruning, etc.)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                }
            ],
            "source": [
                "# BLOCK 5: Actions vs Transformations Demo\n",
                "# ==========================================\n",
                "# Show the difference between lazy transformations and eager actions\n",
                "\n",
                "print(\"\\n=== ACTIONS VS TRANSFORMATIONS DEMONSTRATION ===\")\n",
                "\n",
                "print(\"\\n1. TRANSFORMATIONS (Lazy - No execution):\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "# Build a series of transformations (none execute yet)\n",
                "print(\"Building transformation pipeline...\")\n",
                "\n",
                "transform_1 = df_with_pitcher_batter.filter(col(\"release_speed\") > 85)\n",
                "print(f\"  1. Filter speed > 85: Created (no computation)\")\n",
                "\n",
                "transform_2 = transform_1.filter(col(\"pitch_type\").isin(\"FF\", \"SL\", \"CU\"))\n",
                "print(f\"  2. Filter pitch type: Created (no computation)\")\n",
                "\n",
                "transform_3 = transform_2.withColumn(\n",
                "    \"speed_category\",\n",
                "    when(col(\"release_speed\") > 95, \"Very Fast\").otherwise(\"Fast\")\n",
                ")\n",
                "print(f\"  3. Add speed_category column: Created (no computation)\")\n",
                "\n",
                "transform_4 = transform_3.select(\n",
                "    \"pitcher\", \"release_speed\", \"pitch_type\", \"speed_category\"\n",
                ")\n",
                "print(f\"  4. Select columns: Created (no computation)\")\n",
                "\n",
                "print(\"\\nExecution Plan (no compute yet):\")\n",
                "transform_4.explain(mode=\"simple\")\n",
                "\n",
                "print(\"\\n2. ACTIONS (Eager - Force execution):\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "# Action 1: count (triggers full computation)\n",
                "print(\"\\nExecuting ACTION: .count()\")\n",
                "start_action1 = time.time()\n",
                "count_result = transform_4.count()\n",
                "time_action1 = time.time() - start_action1\n",
                "print(f\"  Result: {count_result:,} rows\")\n",
                "print(f\"  Time: {time_action1:.3f}s\")\n",
                "\n",
                "# Action 2: show (displays first few rows and triggers computation)\n",
                "print(\"\\nExecuting ACTION: .show(3)\")\n",
                "start_action2 = time.time()\n",
                "transform_4.show(3, truncate=False)\n",
                "time_action2 = time.time() - start_action2\n",
                "print(f\"  Time to show: {time_action2:.3f}s\")\n",
                "\n",
                "# Action 3: collect (gathers results back to driver)\n",
                "print(\"\\nExecuting ACTION: .collect() (small sample)\")\n",
                "sample_collect = transform_4.sample(False, 0.001, seed=42)\n",
                "start_action3 = time.time()\n",
                "collected = sample_collect.collect()\n",
                "time_action3 = time.time() - start_action3\n",
                "print(f\"  Collected {len(collected)} rows back to driver\")\n",
                "print(f\"  Time: {time_action3:.3f}s\")\n",
                "\n",
                "print(\"\"\"\n",
                "\\n3. KEY INSIGHTS:\n",
                "   - Transformations (filter, withColumn, select) are LAZY: they don't execute immediately\n",
                "   - They only execute when an ACTION is called (count, show, collect, write, etc.)\n",
                "   - Spark can optimize the entire pipeline by seeing all transformations before execution\n",
                "   - This enables query optimization (filter pushdown, column pruning, etc.)\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "e7a1665f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== MACHINE LEARNING: PITCH TYPE CLASSIFICATION ===\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ML Dataset: 3,133,809 rows with complete features\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training sample: 157,491 rows\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train: 126,185 rows, Test: 31,306 rows\n",
                        "\n",
                        "Training Random Forest Classifier...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training completed in 8.313s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Model Performance:\n",
                        "  ROC-AUC Score: 0.9262\n",
                        "\n",
                        "Feature Importances:\n",
                        "  release_speed: 0.2297\n",
                        "  vx0: 0.0021\n",
                        "  vy0: 0.0546\n",
                        "  vz0: 0.0004\n",
                        "  ax: 0.0344\n",
                        "  ay: 0.1438\n",
                        "  az: 0.5351\n",
                        "\n",
                        "Sample Predictions (first 10):\n",
                        "+-----+----------+--------------------+\n",
                        "|label|prediction|         probability|\n",
                        "+-----+----------+--------------------+\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "+-----+----------+--------------------+\n",
                        "only showing top 10 rows\n",
                        "\n",
                        "ML Task Summary:\n",
                        "  Task: Classify if a pitch is a fastball based on release speed and pitch trajectory (vx0, vy0, vz0, ax, ay, az)\n",
                        "  Algorithm: Random Forest Classifier (10 trees, max depth 5)\n",
                        "  Training time: 8.313s on 5% sample (~360k rows)\n",
                        "  ROC-AUC Score: 0.9262 (higher is better, 0.5=random, 1.0=perfect)\n",
                        "+-----+----------+--------------------+\n",
                        "|label|prediction|         probability|\n",
                        "+-----+----------+--------------------+\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "|    0|       0.0|[0.93722465860663...|\n",
                        "+-----+----------+--------------------+\n",
                        "only showing top 10 rows\n",
                        "\n",
                        "ML Task Summary:\n",
                        "  Task: Classify if a pitch is a fastball based on release speed and pitch trajectory (vx0, vy0, vz0, ax, ay, az)\n",
                        "  Algorithm: Random Forest Classifier (10 trees, max depth 5)\n",
                        "  Training time: 8.313s on 5% sample (~360k rows)\n",
                        "  ROC-AUC Score: 0.9262 (higher is better, 0.5=random, 1.0=perfect)\n"
                    ]
                }
            ],
            "source": [
                "# BLOCK 6: Machine Learning Example (Classification)\n",
                "# =====================================================\n",
                "# Predict pitch type (fastball vs breaking) using pitch trajectory features\n",
                "\n",
                "print(\"\\n=== MACHINE LEARNING: PITCH TYPE CLASSIFICATION ===\")\n",
                "\n",
                "# Prepare data for ML: create binary classification (fastball=1, other=0)\n",
                "# Use pitch trajectory features (vx0, vy0, vz0, ax, ay, az) which have complete data\n",
                "ml_df = df_with_pitcher_batter.select(\n",
                "    col(\"is_fastball\").alias(\"label\"),  # Target: 1=fastball, 0=other\n",
                "    col(\"release_speed\").alias(\"release_speed\"),\n",
                "    col(\"vx0\").alias(\"vx0\"),  # Velocity X component\n",
                "    col(\"vy0\").alias(\"vy0\"),  # Velocity Y component\n",
                "    col(\"vz0\").alias(\"vz0\"),  # Velocity Z component\n",
                "    col(\"ax\").alias(\"ax\"),     # Acceleration X\n",
                "    col(\"ay\").alias(\"ay\"),     # Acceleration Y\n",
                "    col(\"az\").alias(\"az\")      # Acceleration Z (gravity)\n",
                ").filter(\n",
                "    col(\"label\").isNotNull() &\n",
                "    col(\"release_speed\").isNotNull() &\n",
                "    col(\"vx0\").isNotNull() &\n",
                "    col(\"vy0\").isNotNull() &\n",
                "    col(\"vz0\").isNotNull()\n",
                ").na.drop()\n",
                "\n",
                "print(f\"ML Dataset: {ml_df.count():,} rows with complete features\")\n",
                "\n",
                "# Sample data for faster training (use 5% for demo)\n",
                "ml_sample = ml_df.sample(False, 0.05, seed=42)\n",
                "print(f\"Training sample: {ml_sample.count():,} rows\")\n",
                "\n",
                "# Split into train and test\n",
                "train_df, test_df = ml_sample.randomSplit([0.8, 0.2], seed=42)\n",
                "print(f\"Train: {train_df.count():,} rows, Test: {test_df.count():,} rows\")\n",
                "\n",
                "# Build feature vector\n",
                "assembler = VectorAssembler(\n",
                "    inputCols=[\"release_speed\", \"vx0\", \"vy0\", \"vz0\", \"ax\", \"ay\", \"az\"],\n",
                "    outputCol=\"features\"\n",
                ")\n",
                "train_vectors = assembler.transform(train_df).select(\"label\", \"features\")\n",
                "test_vectors = assembler.transform(test_df).select(\"label\", \"features\")\n",
                "\n",
                "# Train Random Forest Classifier\n",
                "print(\"\\nTraining Random Forest Classifier...\")\n",
                "start_train = time.time()\n",
                "\n",
                "rf = RandomForestClassifier(\n",
                "    labelCol=\"label\",\n",
                "    featuresCol=\"features\",\n",
                "    numTrees=10,\n",
                "    maxDepth=5,\n",
                "    seed=42\n",
                ")\n",
                "model = rf.fit(train_vectors)\n",
                "train_time = time.time() - start_train\n",
                "print(f\"Training completed in {train_time:.3f}s\")\n",
                "\n",
                "# Evaluate on test set\n",
                "predictions = model.transform(test_vectors)\n",
                "evaluator = BinaryClassificationEvaluator(\n",
                "    labelCol=\"label\",\n",
                "    rawPredictionCol=\"rawPrediction\",\n",
                "    metricName=\"areaUnderROC\"\n",
                ")\n",
                "auc = evaluator.evaluate(predictions)\n",
                "\n",
                "print(f\"\\nModel Performance:\")\n",
                "print(f\"  ROC-AUC Score: {auc:.4f}\")\n",
                "\n",
                "# Show feature importances\n",
                "print(f\"\\nFeature Importances:\")\n",
                "features = [\"release_speed\", \"vx0\", \"vy0\", \"vz0\", \"ax\", \"ay\", \"az\"]\n",
                "for i, importance in enumerate(model.featureImportances):\n",
                "    print(f\"  {features[i]}: {importance:.4f}\")\n",
                "\n",
                "# Sample predictions\n",
                "print(f\"\\nSample Predictions (first 10):\")\n",
                "predictions.select(\"label\", \"prediction\", \"probability\").show(10)\n",
                "\n",
                "print(\"\\nML Task Summary:\")\n",
                "print(f\"  Task: Classify if a pitch is a fastball based on release speed and pitch trajectory (vx0, vy0, vz0, ax, ay, az)\")\n",
                "print(f\"  Algorithm: Random Forest Classifier (10 trees, max depth 5)\")\n",
                "print(f\"  Training time: {train_time:.3f}s on 5% sample (~360k rows)\")\n",
                "print(f\"  ROC-AUC Score: {auc:.4f} (higher is better, 0.5=random, 1.0=perfect)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "e0a1a6a5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== Analysis Complete ===\n",
                        "Summary:\n",
                        "  - Loaded 5 years of Statcast data (2017-2021)\n",
                        "  - Total records processed: 3,149,505\n",
                        "  - Generated SQL results in ./output/\n",
                        "  - Demonstrated caching, actions vs transformations, and ML classification\n",
                        "  - Total records processed: 3,149,505\n",
                        "  - Generated SQL results in ./output/\n",
                        "  - Demonstrated caching, actions vs transformations, and ML classification\n",
                        "\n",
                        "Spark session stopped.\n",
                        "\n",
                        "Spark session stopped.\n"
                    ]
                }
            ],
            "source": [
                "# Final cleanup\n",
                "print(\"\\n=== Analysis Complete ===\")\n",
                "print(\"Summary:\")\n",
                "print(f\"  - Loaded 5 years of Statcast data (2017-2021)\")\n",
                "print(f\"  - Total records processed: {df_raw.count():,}\")\n",
                "print(f\"  - Generated SQL results in ./output/\")\n",
                "print(f\"  - Demonstrated caching, actions vs transformations, and ML classification\")\n",
                "\n",
                "# Stop Spark\n",
                "spark.stop()\n",
                "print(\"\\nSpark session stopped.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
